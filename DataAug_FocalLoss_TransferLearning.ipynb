{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DataAug_FocalLoss_TransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMpe_-cMEWCJ"
      },
      "source": [
        "\n",
        "This file documents the code that contributes to Experments related to Implement Focal Loss, Data (Image and text) Augmentation, Transfer Learning. \n",
        "\n",
        "\n",
        "They are described in the corresponding sections. The sections before them are necessary data/baseline model code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNwurgfRQ22i"
      },
      "source": [
        "\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive\n",
        "%cd /content/drive/My Drive\n",
        "%pwd\n",
        "%mkdir dl_project\n",
        "%cd /content/drive/My Drive/dl_project\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GB5vsHLL0Pdz"
      },
      "source": [
        "from google.colab import drive # import drive from google colab\n",
        "%cp -v /content/drive/MyDrive/dl_project/* /content/\n",
        "%cd /content/\n",
        "drive.flush_and_unmount()\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BJEdut-2Efk"
      },
      "source": [
        "# Install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XJxRAc963FE"
      },
      "source": [
        "Install Pytorch 1.6.0+cu101"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvIrwQjDgyjz"
      },
      "source": [
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "%pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OneA8Ppn7GIu"
      },
      "source": [
        "Install mmf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46BTMy4fYk8e"
      },
      "source": [
        "\n",
        "#!git clone https://github.com/facebookresearch/mmf.git\n",
        "%cd mmf\n",
        "!pip install --editable .\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjkexQFH2Jez"
      },
      "source": [
        "# Check if cuda is enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-CzbK-YZSqn"
      },
      "source": [
        "!nvcc --version\n",
        "import torch\n",
        "torch.cuda.is_available()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGaRIED7Zkm_"
      },
      "source": [
        "url = \"https://drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com/XjiOc5ycDBRRNwbhRlgH.zip?AWSAccessKeyId=AKIARVBOBDCY4MWEDJKS&Signature=3eG839TKaJuE8uryxuYkGvAqMC8%3D&Expires=1606846839\"\n",
        "password = \"EWryfbZyNviilcDF\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDz4UfWb2d7r"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoszjtFj7cG2"
      },
      "source": [
        "url =\"https://drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com/XjiOc5ycDBRRNwbhRlgH.zip?AWSAccessKeyId=AKIARVBOBDCY4MWEDJKS&Signature=vwrcLD1%2FgzoI%2B%2Be4TlMITuWphVg%3D&Expires=1607484815\"\n",
        "password = \"EWryfbZyNviilcDF\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tfPcRoNUuIG"
      },
      "source": [
        "%cd /content/drive/My Drive/dl_project\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGFqLM_gZxbu"
      },
      "source": [
        "!curl -o /content/hm.zip \"$url\" -H 'Referer: https://www.drivendata.org/competitions/64/hateful-memes/data/' --compressed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNgVcXVj3aZD"
      },
      "source": [
        "Zip file into required MMF format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPX0jYdPbBW6"
      },
      "source": [
        "!mmf_convert_hm --zip_file ./hm.zip --password $password --bypass_checksum=1\n",
        "%cd /content/drive/My Drive/dl_project\n",
        "%pwd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I893mq2451SI"
      },
      "source": [
        "# Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_sP7g72cmOH"
      },
      "source": [
        "\n",
        "from mmf.common.registry import registry\n",
        "from mmf.models.mmbt import MMBT\n",
        "from mmf.utils.build import build_dataset\n",
        "from mmf.utils.env import setup_imports\n",
        "setup_imports()\n",
        "dataset = build_dataset(\"hateful_memes\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 20)\n",
        "dataset.visualize(num_samples=8, size=(512, 512), nrow=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt_I8aKm58AT"
      },
      "source": [
        "# Test pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvqd1XX2zfvq"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "from mmf.models.mmbt import MMBT\n",
        "\n",
        "model = MMBT.from_pretrained(\"mmbt.hateful_memes.images\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI06S4UZ6Cry"
      },
      "source": [
        "image_url = \"https://i.imgur.com/tEcsk5q.jpg\" #@param {type:\"string\"}\n",
        "text = \"look how many people love you\" #@param {type: \"string\"}\n",
        "output = model.classify(image_url, text)\n",
        "plt.imshow(Image.open(requests.get(image_url, stream=True).raw))\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "hateful = \"Yes\" if output[\"label\"] == 1 else \"No\"\n",
        "print(\"Hateful as per the model?\", hateful)\n",
        "print(f\"Model's confidence: {output['confidence'] * 100:.3f}%\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eblFos9M6MYp"
      },
      "source": [
        "# Build baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgPH9k8bcX-9"
      },
      "source": [
        "Unzip hm.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p43JJuo5bFiE"
      },
      "source": [
        "%cd content\n",
        "!unzip -P EWryfbZyNviilcDF ./hm.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "487UZvkwzOEm"
      },
      "source": [
        "!mkdir savedata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oay4hfGW5uTL"
      },
      "source": [
        "Implement help functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuIs3DNEzqgl"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "import torchvision.models\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "\n",
        "from keras_preprocessing.sequence  import pad_sequences\n",
        "from sklearn.metrics import accuracy_score, precision_score,recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def read_data(arr, label=False):\n",
        "\n",
        "    df = {}\n",
        "    df[\"id\"] = []\n",
        "    df[\"img_name\"] = []\n",
        "    df[\"text\"] = []\n",
        "\n",
        "    if label:\n",
        "        df[\"label\"] = []\n",
        "\n",
        "    for element in arr:\n",
        "        js = json.loads(element)\n",
        "        df[\"id\"].append(js[\"id\"])\n",
        "        df[\"img_name\"].append(js[\"img\"])\n",
        "        df[\"text\"].append(js[\"text\"])\n",
        "\n",
        "        if label:\n",
        "            df[\"label\"].append(js[\"label\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "class HM_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv, tokenizer, transforms=None, label=False, imagePreLoad = False):\n",
        "        self.csv = csv\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transforms = transforms\n",
        "        self.label = label\n",
        "        self.imagePreLoad = imagePreLoad\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.csv)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx.to_list()\n",
        "        req = self.csv.iloc[idx]\n",
        "        img_name = req.img_name\n",
        "        text = req.text\n",
        "        encoding = self.tokenizer.encode(text)\n",
        "        encoding = pad_sequences([encoding], maxlen=20, padding=\"post\")\n",
        "        mask = encoding.copy()\n",
        "        mask[mask > 0] = 1\n",
        "        if self.imagePreLoad:\n",
        "          img = req.image\n",
        "        else:\n",
        "          img = cv2.imread(\"data/\" + img_name)\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        if self.label:\n",
        "            img_label = [req.label]\n",
        "            sample = {\"image\": img, \"label\": torch.FloatTensor(img_label), \"text\": text,\n",
        "                      \"embeddings\": torch.LongTensor(encoding), \"attn\": torch.FloatTensor(mask)}\n",
        "        else:\n",
        "            sample = {\"image\": img, \"text\": text,\n",
        "                      \"embeddings\": torch.LongTensor(encoding), \"attn\": torch.FloatTensor(mask)}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "def preprocess_data(data_file, label=False, transform = None, return_dataset = False, return_dataframe = False):\n",
        "\n",
        "    with open(data_file) as f:\n",
        "        arr = f.readlines()\n",
        "\n",
        "    data_dict = read_data(arr, label=label)\n",
        "    dataframe = pd.DataFrame(data_dict)\n",
        "    if return_dataframe:\n",
        "      return dataframe\n",
        "    dataset = HM_Dataset(dataframe, tokenizer, transforms=transform, label=label)\n",
        "    if return_dataset:\n",
        "      return dataset\n",
        "    else:\n",
        "      dataloader = DataLoader(dataset, shuffle=True, batch_size=8)\n",
        "      return dataloader\n",
        "\n",
        "    \n",
        "def metrics(out, label, accuracy=True, precision=False, recall=False, specificity = False):\n",
        "    arr = out.detach().cpu().numpy()\n",
        "    mask_0 = arr < 0.5\n",
        "    mask_1 = arr > 0.5\n",
        "    arr[mask_0] = 0\n",
        "    arr[mask_1] = 1\n",
        "    lab = label.cpu().numpy()\n",
        "\n",
        "    ret = []\n",
        "    if accuracy:\n",
        "        acc = np.sum(lab == arr) / len(arr)\n",
        "        ret.append(acc)\n",
        "    if precision:\n",
        "        precision = precision_score(arr, lab)\n",
        "        ret.append(precision)\n",
        "    if recall:\n",
        "        recall = recall_score(arr, lab)\n",
        "        ret.append(recall)\n",
        "    if specificity:\n",
        "\n",
        "        try:\n",
        "          [tn, fp, fn, tp] = confusion_matrix(lab, arr).ravel()\n",
        "          specificity = tn / (tn+fp)\n",
        "        except:\n",
        "          specificity = 0\n",
        "        ret.append(specificity)\n",
        "\n",
        "\n",
        "    return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rguCZ18I5ngE"
      },
      "source": [
        "# Implement Focal Loss\n",
        "Reference: 1. https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/8\n",
        "2. Deep Learning Class Assignment 2 Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AptGey_0Sfv"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def reweight(cls_num_list, beta=0.9999):\n",
        "    '''\n",
        "    Implement reweighting by effective numbers\n",
        "    :param cls_num_list: a list containing # of samples of each class\n",
        "    :param beta: hyper-parameter for reweighting, see paper for more details\n",
        "    :return:\n",
        "    '''\n",
        "    per_cls_weights = None\n",
        "    #############################################################################\n",
        "    # TODO: reweight each class by effective numbers                            #\n",
        "    #############################################################################\n",
        "    cls_num_list = cls_num_list.cpu()\n",
        "    C = len(cls_num_list)\n",
        "    per_cls_weights = (1-beta)/(1-beta**np.array(cls_num_list))\n",
        "    per_cls_weights = per_cls_weights/np.sum(per_cls_weights)*C #Normalize\n",
        "    per_cls_weights = torch.from_numpy(per_cls_weights)\n",
        "    #############################################################################\n",
        "    #                              END OF YOUR CODE                             #\n",
        "    #############################################################################\n",
        "    per_cls_weights = per_cls_weights.cuda()\n",
        "    return per_cls_weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \n",
        "    def __init__(self, weight=None, \n",
        "                 gamma=1., reduction='none'):\n",
        "        nn.Module.__init__(self)\n",
        "        self.weight = weight\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        \n",
        "    def forward(self, input, target):\n",
        "        #target = torch.gt(target, 0.5)\n",
        "        #target = target.type(torch.int64)\n",
        "        weight = self.weight\n",
        "        target_bi = torch.gt(target, 0.5)\n",
        "        target_bi = target_bi.type(torch.int64)\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "        target_bi.to(device)\n",
        "\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(input, target, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss) # prevents nans when probability 0\n",
        "        F_loss = (1-pt)**self.gamma * BCE_loss\n",
        "\n",
        "\n",
        "        if self.weight is None:#No reweighting\n",
        "            F_loss = (1-pt)**self.gamma * BCE_loss\n",
        "        else: #reweigthing\n",
        "            weight.to(device)\n",
        "            w = weight.gather(0,target_bi.data.view(-1))\n",
        "            F_loss = torch.autograd.Variable(w) * BCE_loss * (1-pt)**self.gamma\n",
        "\n",
        "        return F_loss.mean()\n",
        "\n",
        "\n",
        "#https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/8\n",
        "def get_cls_num_list(train_df):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    return torch.tensor([sum(train_df['label']==0),sum(train_df['label']==1)],device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLu8qa6y6Yw7"
      },
      "source": [
        "class VGG(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VGG, self).__init__()\n",
        "    torchvision.models.vgg.model_urls['vgg16'] = torchvision.models.vgg.model_urls['vgg16'].replace('https://', 'http://')\n",
        "    vgg = torchvision.models.vgg16(pretrained=True)\n",
        "    self.model = torch.nn.Sequential(*(list(vgg.children())[:-1]))\n",
        "    self.pooling = torch.nn.MaxPool2d(kernel_size=3)\n",
        "    self.flat_layer = nn.Flatten()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.model(x)\n",
        "    x = self.pooling(x)\n",
        "    out = self.flat_layer(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Resnet,self).__init__()\n",
        "    torchvision.models.resnet.model_urls['resnet18'] = torchvision.models.resnet.model_urls['resnet18'].replace('https://', 'http://')\n",
        "    resnet = torchvision.models.resnet18(pretrained=True)\n",
        "    self.model = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
        "    self.pooling = torch.nn.MaxPool2d(kernel_size=3)\n",
        "    self.flat_layer = nn.Flatten()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.model(x)\n",
        "    out = self.flat_layer(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Mobilenet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Mobilenet,self).__init__()\n",
        "    torchvision.models.mobilenet.model_urls['mobilenet_v2'] = torchvision.models.mobilenet.model_urls['mobilenet_v2'].replace('https://', 'http://')\n",
        "    mobilenet = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "    self.model = torch.nn.Sequential(*(list(mobilenet.children())[:-1]))\n",
        "    self.pooling = torch.nn.MaxPool2d(kernel_size=3)\n",
        "    self.flat_layer = nn.Flatten()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.model(x)\n",
        "    x = self.pooling(x)\n",
        "    out = self.flat_layer(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Ensemble(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Ensemble,self).__init__()\n",
        "    self.vgg = VGG()\n",
        "    self.res= Resnet()\n",
        "    self.mobile = Mobilenet()\n",
        "    self.fc_b1 = nn.Sequential(nn.Linear(7680,6000),\n",
        "                               nn.BatchNorm1d(6000))\n",
        "    self.d1 = nn.Dropout(0.6)\n",
        "    self.fc_b2 = nn.Sequential(nn.Linear(6000,3000),\n",
        "                               nn.BatchNorm1d(3000))\n",
        "    self.d2 = nn.Dropout(0.6)\n",
        "    self.fc3 = nn.Linear(3000,768)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x1 = self.vgg(x)\n",
        "    x2 = self.res(x)\n",
        "    x3 = self.mobile(x)\n",
        "    out_1 = torch.cat([x1,x2,x3],dim=1)\n",
        "    out_1 = self.d1(self.fc_b1(out_1))\n",
        "    out_1 = self.d2(self.fc_b2(out_1))\n",
        "    out = self.fc3(out_1)\n",
        "    return out\n",
        "\n",
        "\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.pooling = nn.AvgPool1d(kernel_size=3)\n",
        "        self.flat_layer = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        self.fc3 = nn.Linear(5120, 768)\n",
        "\n",
        "    def forward(self, x, attn):\n",
        "        x = self.model(input_ids=x.squeeze(1), encoder_attention_mask=attn)[0]\n",
        "        x = self.pooling(x)\n",
        "        x = self.flat_layer(x)\n",
        "        out = F.relu(self.fc3(x), inplace=False)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Base_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Base_Model, self).__init__()\n",
        "        self.bert_part = BERT()\n",
        "        self.batch_norm = nn.BatchNorm1d(6000)\n",
        "        self.ensemble = Ensemble()\n",
        "        self.fc1 = nn.Linear(1536, 6000)\n",
        "        self.fc2 = nn.Linear(6000, 3000)\n",
        "        self.fc3 = nn.Linear(3000, 1)\n",
        "\n",
        "    def forward(self, image, text, attn):\n",
        "        x1 = self.ensemble(image)\n",
        "        x2 = self.bert_part(text, attn)\n",
        "\n",
        "        x3 = self.fc1(torch.cat((x1, x2), dim=1))\n",
        "        x3 = self.batch_norm(x3)\n",
        "        x4 = F.relu(self.fc2(x3), inplace=False)\n",
        "        out_1 = self.fc3(x4)\n",
        "        out = torch.sigmoid(out_1)\n",
        "        return out\n",
        "\n",
        "    def fit(self, train_data, valid_data=None, epochs=3,loss_type = \"BCE\", cls_num_list = None, beta = 0.9999):\n",
        "        losses = []\n",
        "        losses_val = []\n",
        "        losses_step = {}\n",
        "        losses_val_step = {}\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        optim = Adam(self.parameters(), lr=1e-5, weight_decay=0.001)\n",
        "\n",
        "        if cls_num_list is not None:\n",
        "            per_cls_weights = reweight(cls_num_list, beta=beta)\n",
        "            #if torch.cuda.is_available():\n",
        "            #    per_cls_weights = per_cls_weights.cuda()\n",
        "        else:\n",
        "            per_cls_weights = None\n",
        "\n",
        "        if loss_type == \"BCE\":\n",
        "            criterion = nn.BCELoss()\n",
        "        else:\n",
        "            criterion = FocalLoss(weight=per_cls_weights, gamma=1)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            print(\"===================== Training ====================\")\n",
        "            print(\"Epoch # \", epoch + 1)\n",
        "            train_loss = 0.0\n",
        "            train_acc = 0.0\n",
        "            train_pre = 0.0\n",
        "            train_rec = 0.0\n",
        "            train_spe = 0.0\n",
        "            losses_step[epoch] = []\n",
        "            losses_val_step[epoch] = []\n",
        "\n",
        "            for num, batch in enumerate(train_data):\n",
        "                img, embeddings, label = batch[\"image\"].to(device), batch[\"embeddings\"].to(device), batch[\"label\"].to(\n",
        "                    device)\n",
        "                mask = batch[\"attn\"].to(device)\n",
        "                out = self.forward(img, embeddings, mask)\n",
        "\n",
        "                loss = criterion(out, label)\n",
        "                train_loss += loss.item()\n",
        "                [acc, prec, rec, spe] = metrics(out, label, accuracy=True, precision=True, recall=True, specificity = True)\n",
        "                train_acc += acc\n",
        "                train_pre += prec\n",
        "                train_rec += rec\n",
        "                train_spe += spe\n",
        "\n",
        "                losses_step[epoch].append([loss.item(),acc,prec,rec,spe])\n",
        "\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                \n",
        "\n",
        "                if num > 0 and num % 100 == 0:\n",
        "                    print(\"Loss after \", num, \" steps: \", train_loss / num)\n",
        "                    print(\"Accuracy after \", num, \" steps: \", train_acc / num)\n",
        "                    print(\"Precision after \", num, \" steps: \", train_pre / num)\n",
        "                    print(\"Recall after \", num, \" steps: \", train_rec / num)\n",
        "                    print(\"specificity after \", num, \" steps: \", train_spe / num)\n",
        "\n",
        "                    # print(\"Actual Output: \",label)\n",
        "                    # print(\"Predicted Output: \",out)\n",
        "\n",
        "            losses.append([train_loss / len(train_data),train_acc / num,train_pre / num, train_rec / num,train_spe / num])\n",
        "            print(\"----------------After epoch \", epoch + 1, \"-------------------------\")\n",
        "            print(\"Loss after \", num, \" steps: \", train_loss / num)\n",
        "            print(\"Accuracy after \", num, \" steps: \", train_acc / num)\n",
        "            print(\"Precision after \", num, \" steps: \", train_pre / num)\n",
        "            print(\"Recall after \", num, \" steps: \", train_rec / num)\n",
        "            print(\"specificity after \", num, \" steps: \", train_spe / num)\n",
        "\n",
        "            self.eval()\n",
        "            print(\"=====================Validating=====================\")\n",
        "            eval_acc = 0.0\n",
        "            eval_loss = 0.0\n",
        "            eval_prec = 0.0\n",
        "            eval_rec = 0.0\n",
        "            eval_spe = 0.0\n",
        "            if valid_data:\n",
        "              for num,batch in enumerate(valid_data):\n",
        "                img,embeddings,label = batch[\"image\"].to(device),batch[\"embeddings\"].to(device),batch[\"label\"].to(device)\n",
        "                mask = batch[\"attn\"].to(device)\n",
        "                out = self.forward(img,embeddings,mask)\n",
        "              \n",
        "                loss = criterion(out,label)\n",
        "\n",
        "                eval_loss+=loss.item()\n",
        "                [acc,precision,recall,spe] = metrics(out,label,True,True,True, True)\n",
        "                eval_acc+=acc\n",
        "                eval_prec+=precision \n",
        "                eval_rec+=recall\n",
        "                eval_spe += spe\n",
        "\n",
        "                losses_val_step[epoch].append([loss.item(),acc,precision,recall,spe])\n",
        "\n",
        "                if num == 5:\n",
        "                  print(\"Actual Labels: \",label)\n",
        "                  arr = out\n",
        "                  print(\"Predicted Labels\",arr)\n",
        "              print(\"Val_loss after \",epoch+1,\" epochs: \",eval_loss/len(valid_data))\n",
        "              losses_val.append([eval_loss/len(valid_data),eval_acc/len(valid_data),eval_prec /len(valid_data), eval_rec /len(valid_data), eval_spe /len(valid_data)])\n",
        "\n",
        "              print(\"Val_accuracy after \",epoch+1,\" epochs: \",eval_acc/len(valid_data))\n",
        "              print(\"Val_precision after \",epoch+1,\" epochs: \",eval_prec/len(valid_data))\n",
        "              print(\"Val_recall after \",epoch+1,\" epochs: \",eval_rec/len(valid_data))\n",
        "              print(\"Val_specificity after \",epoch+1,\" epochs: \",eval_spe/len(valid_data))\n",
        "        return losses, losses_val, losses_step, losses_val_step\n",
        "\n",
        "#https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjVhHqtU968W"
      },
      "source": [
        "def constuct_loss_stuct(losses, losses_val, losses_step, losses_val_step):\n",
        "  loss_struct = {}\n",
        "  loss_struct['losses'] = losses\n",
        "  loss_struct['losses_val'] = losses_val\n",
        "  loss_struct['losses_step'] = losses_step\n",
        "  loss_struct['losses_val_step'] = losses_val_step\n",
        "\n",
        "  return loss_struct\n",
        "\n",
        "import pickle\n",
        "\n",
        "def pickle_loss(loss_struct, name):\n",
        "  f = open('savedata/'+name+'.pckl', 'wb')\n",
        "  pickle.dump(loss_struct, f)\n",
        "  f.close()\n",
        "  #f = open('savedata/loss_struct.pckl', 'rb')\n",
        "  #loss_struct2 = pickle.load(f)\n",
        "  #f.close()\n",
        "\n",
        "def read_pickle_data(name):\n",
        "  f = open('savedata/'+name+'.pckl', 'rb')\n",
        "  df = pickle.load(f)\n",
        "  f.close()\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQIUJfnq6GBN"
      },
      "source": [
        "**Train** baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDiViLYVVhVG"
      },
      "source": [
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "\n",
        "train_data = preprocess_data(\"data/train.jsonl\", label=True, transform = transform)\n",
        "valid_data = preprocess_data(\"data/dev_seen.jsonl\", label=True, transform = transform)\n",
        "#test_data = preprocess_data(\"data/test_seen.jsonl\", label=False, transform = transform)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = Base_Model()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "num_epochs=10\n",
        "losses, losses_val, losses_step, losses_val_step = model.fit(train_data, valid_data, epochs=num_epochs)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i16THq6V1zK"
      },
      "source": [
        "Focal Loss with reweighting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3DPPluPOImC"
      },
      "source": [
        "batch_size = 8\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "\n",
        "train_df = preprocess_data(\"data/train.jsonl\", label=True, transform = transform, return_dataframe=True)\n",
        "cls_num_list = get_cls_num_list(train_df)\n",
        "\n",
        "train_data = preprocess_data(\"data/train.jsonl\", label=True, transform = transform)\n",
        "valid_data = preprocess_data(\"data/dev_seen.jsonl\", label=True, transform = transform)\n",
        "#test_data = preprocess_data(\"data/test_seen.jsonl\", label=False, transform = transform)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = Base_Model()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "num_epochs=20\n",
        "losses, losses_val, losses_step, losses_val_step = model.fit(train_data, valid_data, epochs=num_epochs, loss_type = \"Focal\", cls_num_list = cls_num_list)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDEBWIs6Wufz"
      },
      "source": [
        "Focal Loss without reweighting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25VnkqgCOprO"
      },
      "source": [
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "\n",
        "train_data = preprocess_data(\"data/train.jsonl\", label=True, transform = transform)\n",
        "valid_data = preprocess_data(\"data/dev_seen.jsonl\", label=True, transform = transform)\n",
        "#test_data = preprocess_data(\"data/test_seen.jsonl\", label=False, transform = transform)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = Base_Model()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "num_epochs=20\n",
        "losses, losses_val, losses_step, losses_val_step = model.fit(train_data, valid_data, epochs=num_epochs, loss_type = \"Focal\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeVnXuz7-G53"
      },
      "source": [
        "# Data (Image and text) Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btX1e9Z6171m"
      },
      "source": [
        "def load_dataset(data_file, transform=None, label=False):\n",
        "\n",
        "    with open(data_file) as f:\n",
        "        arr = f.readlines()\n",
        "\n",
        "    data_dict = read_data(arr, label=label)\n",
        "    dataframe = pd.DataFrame(data_dict)\n",
        "    dataset = HM_Dataset(dataframe, tokenizer, transforms=transform, label=label)\n",
        "    #dataloader = DataLoader(dataset, shuffle=True, batch_size=8)\n",
        "\n",
        "    return dataset\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVcIaGRarn8A"
      },
      "source": [
        "# Image Augmentation\n",
        "trans = transforms.Compose([transforms.ToPILImage(), \n",
        "                          transforms.Resize((224, 224)), \n",
        "                          transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4),\n",
        "                          transforms.RandomRotation(20),\n",
        "                          transforms.RandomVerticalFlip(0.1),\n",
        "                          transforms.Resize((224, 224)), \n",
        "                          transforms.ToTensor()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNyuQT-k1YDP"
      },
      "source": [
        "Custom functions to add words/sentences to the meme images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVKhspOLLrVn"
      },
      "source": [
        "from PIL import Image, ImageDraw\n",
        "from PIL import ImageFont\n",
        "\n",
        "#Reference: https://stackoverflow.com/questions/41556771/is-there-a-way-to-outline-text-with-a-dark-line-in-pil\n",
        "def add_subtitle(\n",
        "    bg,\n",
        "    text=\"nice\",\n",
        "    xy=(\"center\", 50),\n",
        "    font=\"arial.ttf\",\n",
        "    font_size=24,\n",
        "    font_color=(255, 255, 255),\n",
        "    stroke=2,\n",
        "    stroke_color=(0, 0, 0),\n",
        "    shadow=(4, 4),\n",
        "    shadow_color=(0, 0, 0),\n",
        "):\n",
        "    \"\"\"draw subtitle on image by pillow\n",
        "    Args:\n",
        "        bg(PIL image): image to add subtitle\n",
        "        text(str): subtitle\n",
        "        xy(tuple): absolute top left location of subtitle\n",
        "        ...: extra style of subtitle\n",
        "    Returns:\n",
        "        bg(PIL image): image with subtitle\n",
        "    \"\"\"\n",
        "    stroke_width = stroke\n",
        "    xy = list(xy)\n",
        "    W, H = bg.width, bg.height\n",
        "    font = ImageFont.truetype(str(font), font_size)\n",
        "    w, h = font.getsize(text, stroke_width=stroke_width)\n",
        "    if xy[0] == \"center\":\n",
        "        xy[0] = (W - w) // 2\n",
        "    if xy[1] == \"center\":\n",
        "        xy[1] = (H - h) // 2\n",
        "    draw = ImageDraw.Draw(bg)\n",
        "    if shadow:\n",
        "        draw.multiline_text(\n",
        "            (xy[0] + shadow[0], xy[1] + shadow[1]), text, font=font, fill=shadow_color\n",
        "        )\n",
        "    draw.multiline_text(\n",
        "        (xy[0], xy[1]),\n",
        "        text,\n",
        "        font=font,\n",
        "        fill=font_color,\n",
        "        stroke_width=stroke_width,\n",
        "        stroke_fill=stroke_color,\n",
        "    )\n",
        "    return bg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FegQg9hFKCo4"
      },
      "source": [
        "#Download font\n",
        "!curl https://www.freefontspro.com/d/14454/arial.zip -o ./arial.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-XzW2JC1jql"
      },
      "source": [
        "!unzip ./arial.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gi7ezSd8IPx"
      },
      "source": [
        "def read_text_and_label(arr):\n",
        "    df = {}\n",
        "    df[\"text\"] = []\n",
        "    df[\"label\"] = []\n",
        "\n",
        "    for element in arr:\n",
        "        js = json.loads(element)\n",
        "        df[\"text\"].append(js[\"text\"])\n",
        "        df[\"label\"].append(js[\"label\"])\n",
        "    return df\n",
        "\n",
        "def construct_text_library(data_file):\n",
        "    with open(data_file) as f:\n",
        "        arr = f.readlines()\n",
        "    data_dict = read_text_and_label(arr)\n",
        "    return data_dict\n",
        "    \n",
        "data_file = \"data/train.jsonl\"\n",
        "\n",
        "text_dict = construct_text_library(data_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_J0g8pw92_l"
      },
      "source": [
        "\n",
        "import progressbar\n",
        "def read_data_with_text_augmentation(arr, text_dict, sample_size):\n",
        "\n",
        "    df = {}\n",
        "    df[\"id\"] = []\n",
        "    df[\"img_name\"] = []\n",
        "    df[\"image\"] = []\n",
        "    df[\"text\"] = []\n",
        "    df[\"label\"] = []\n",
        "\n",
        "    idx_arr = np.random.randint(0,len(arr),size = sample_size)\n",
        "    idx_lib = np.random.randint(0,len(text_dict['label']),size = sample_size)\n",
        "\n",
        "    for ki in progressbar.progressbar(range(sample_size)):\n",
        "        ei = idx_arr[ki]\n",
        "        li = idx_lib[ki]\n",
        "\n",
        "        element = arr[ei]\n",
        "        js = json.loads(element)\n",
        "        df[\"id\"].append(js[\"id\"])\n",
        "        df[\"img_name\"].append(js[\"img\"])\n",
        "        txt = text_dict['text'][li]\n",
        "        new_text = js[\"text\"] + \" \" + txt\n",
        "        img_arr = cv2.imread(\"data/\" + js[\"img\"])\n",
        "\n",
        "        ntxt = len(txt)\n",
        "        mtxt = int(ntxt/2)\n",
        "\n",
        "        img2 = transforms.ToPILImage(mode='RGB')(img_arr)\n",
        "        add_subtitle(img2, txt[0:mtxt]+\"\\n\"+txt[mtxt:],xy=(\"center\", \"center\"))\n",
        "        img2 = transforms.ToTensor()(img2)\n",
        "\n",
        "        df[\"text\"].append(new_text)\n",
        "        df[\"image\"].append(img2)\n",
        "        df[\"label\"].append(max(js[\"label\"],text_dict['label'][li]))\n",
        "        \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psFGGcod8ah-"
      },
      "source": [
        "\n",
        "def aug_trainingdata_with_text(data_file, text_dict, transform=None, sample_size = 1000, return_dataset= False):\n",
        "  with open(data_file) as f:\n",
        "      arr = f.readlines()\n",
        "\n",
        "  data_dict = read_data_with_text_augmentation(arr, text_dict, sample_size)\n",
        "  dataframe = pd.DataFrame(data_dict)\n",
        "  dataset = HM_Dataset(dataframe, tokenizer, transforms = transform, label = True, imagePreLoad = True)\n",
        "  if return_dataset:\n",
        "    return dataset\n",
        "  else:\n",
        "    dataloader = DataLoader(dataset, shuffle=True, batch_size=8)\n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9B9KzotyqDy"
      },
      "source": [
        "train_dataset = preprocess_data(\"data/train.jsonl\", label=True, transform = transform, return_dataset = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJByny2qSTHu"
      },
      "source": [
        "data_file = \"data/train.jsonl\"\n",
        "with open(data_file) as f:\n",
        "    arr = f.readlines()\n",
        "\n",
        "data_dict = read_data(arr, label=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHieu74kzXvj"
      },
      "source": [
        "trans_aug = transforms.Compose([transforms.ToPILImage(), \n",
        "                          transforms.Resize((224, 224)), \n",
        "                          transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4),\n",
        "                          transforms.RandomRotation(20),\n",
        "                          transforms.RandomVerticalFlip(0.1),\n",
        "                          transforms.Resize((224, 224)), \n",
        "                          transforms.ToTensor()])\n",
        "aug_img_train_dataset = preprocess_data(\"data/train.jsonl\",label=True, transform = trans_aug, return_dataset = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCqgH0IhyFon"
      },
      "source": [
        "aug_text_train_dataset = aug_trainingdata_with_text(data_file, text_dict, transform = transform, sample_size = 3000, return_dataset= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF0phtLYtpw9"
      },
      "source": [
        "augmented_train_dataset = torch.utils.data.ConcatDataset([train_dataset,aug_img_train_dataset,aug_text_train_dataset])\n",
        "augmented_train_data = DataLoader(augmented_train_dataset, shuffle=True, batch_size=8)\n",
        "del train_dataset\n",
        "del aug_img_train_dataset\n",
        "del aug_text_train_dataset\n",
        "del augmented_train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZwsJZMux8nf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HfzEtO_Rucqb"
      },
      "source": [
        "valid_data = preprocess_data(\"data/dev_seen.jsonl\", label=True, transform = transform)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = Base_Model()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "num_epochs=10\n",
        "losses, losses_val, losses_step, losses_val_step = model.fit(augmented_train_data, valid_data, epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swK-XMb046Hz"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4wdhUoT2OXl"
      },
      "source": [
        "Hate Speech and Offensive Language Dataset can be downloaded via: https://www.kaggle.com/mrmorj/hate-speech-and-offensive-language-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1T6bTgQZ6B30"
      },
      "source": [
        "#twitter_labeled_data.csv can be downloaded via:\n",
        "#\n",
        "twitter_df = pd.read_csv('twitter_labeled_data.csv')\n",
        "\n",
        "twitter_df[\"id\"] = twitter_df.index.astype(str)\n",
        "twitter_df[\"img_name\"] = twitter_df[\"id\"] \n",
        "twitter_df[\"image\"] = [torch.rand(3,1,1) for k in range(len(twitter_df))]\n",
        "twitter_df[\"text\"] = twitter_df[\"tweet\"]\n",
        "twitter_df[\"label\"] = (twitter_df[\"class\"]!=2).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "twitter_df_cleaned = twitter_df[[\"id\",\"img_name\",\"image\",\"text\",\"label\"]].sample(10000).copy()\n",
        "twitter_dataset = HM_Dataset(twitter_df_cleaned, tokenizer, transforms = transform, label = True, imagePreLoad = True)\n",
        "\n",
        "twitter_dataloader = DataLoader(twitter_dataset, shuffle=True, batch_size=8)\n",
        "\n",
        "del twitter_df,twitter_df_cleaned, twitter_dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoVEVBPZ6OYm"
      },
      "source": [
        "\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = Base_Model()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "num_epochs=5\n",
        "losses, losses_val, losses_step, losses_val_step = model.fit(twitter_dataloader, epochs=num_epochs)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOHx6M7GYMYs"
      },
      "source": [
        "#Move the presaved model to cache\n",
        "\n",
        "from google.colab import drive # import drive from google colab\n",
        "%cp -v /content/drive/MyDrive/dl_project/savedata/pre_transferlearning_pre_model.pckl /content/savedata/\n",
        "#%cp -v /content/drive/MyDrive/dl_project/hm.zip /content/\n",
        "%cd /content/\n",
        "drive.flush_and_unmount()\n",
        "%pwd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hygOLOdf3opQ"
      },
      "source": [
        "model = read_pickle_data('pre_transferlearning_pre_model')\n",
        "\n",
        "train_data = preprocess_data(\"data/train.jsonl\", label=True, transform = transform)\n",
        "valid_data = preprocess_data(\"data/dev_seen.jsonl\", label=True, transform = transform)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "num_epochs=10\n",
        "losses, losses_val, losses_step, losses_val_step = model.fit(train_data, valid_data, epochs=num_epochs)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nO_7ZhGBzaG"
      },
      "source": [
        "#Transfer learninng with  FREEZING\n",
        "\n",
        "model = read_pickle_data('pre_transferlearning_pre_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPtwK6lLBx0s"
      },
      "source": [
        "\n",
        "#for param in model.parameters():\n",
        "#    param.requires_grad = False\n",
        "\n",
        "named_parameters = list(model.named_parameters())\n",
        "parameters_names = [k[0] for k in named_parameters]\n",
        "\n",
        "set_false_if_contains = ['bert_part.model']\n",
        "set_to_false = []\n",
        "for k, namek in enumerate(parameters_names):\n",
        "    for seti in set_false_if_contains:\n",
        "        if seti in namek:\n",
        "            set_to_false.append(k)\n",
        "params = list(model.parameters())\n",
        "for k in set_to_false:\n",
        "    params[k].requires_grad = False\n",
        "\n",
        "#for param in model.parameters():\n",
        "#    print(param.requires_grad)\n",
        "del named_parameters, parameters_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wmmOiJ-ETw-"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "num_epochs=10\n",
        "losses, losses_val, losses_step, losses_val_step = model.fit(train_data, valid_data, epochs=num_epochs)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}