{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Measuring Model Confidence",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMq1aDY1zCdeFgT6Je+iwAq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e4da092712d475bb18133c4b682b88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80cff50a339647debc0d89a7295be80a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51b6cf58b4e34c2bbec8fd6490e20453",
              "IPY_MODEL_350acb580d054ab2ba9da2e0d07f6cdb",
              "IPY_MODEL_40a559d040954fe1b53ac5f55468537a"
            ]
          }
        },
        "80cff50a339647debc0d89a7295be80a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51b6cf58b4e34c2bbec8fd6490e20453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ea6438e1a0c495eb40ffc319c1fdee3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2730342bd424ba0b468f30a3a19eeef"
          }
        },
        "350acb580d054ab2ba9da2e0d07f6cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68a4bc9e8f7f404eab11680291511c73",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f9e4fec25a14a83aa312e6cab3d70b6"
          }
        },
        "40a559d040954fe1b53ac5f55468537a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4f0e7e0ee1e845f08931d9df99f1e3b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 750kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_591dedb965294038a6949c229b041355"
          }
        },
        "1ea6438e1a0c495eb40ffc319c1fdee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2730342bd424ba0b468f30a3a19eeef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68a4bc9e8f7f404eab11680291511c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f9e4fec25a14a83aa312e6cab3d70b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f0e7e0ee1e845f08931d9df99f1e3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "591dedb965294038a6949c229b041355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shenxinspeed/Team_25_Hatefull_Memes_Project/blob/main/Measuring_Model_Confidence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5CkcBoY4jrZ"
      },
      "source": [
        "# Connect to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egyinOj_4xzR"
      },
      "source": [
        "The google drive is used to store trained models, training results and analysis plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpai0lGoS9N2",
        "outputId": "b933eb79-a6b5-416d-f6a9-9fed3ce72f2a"
      },
      "source": [
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuYyCa8W5AEn"
      },
      "source": [
        "## Create Folders on Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfysDmFS5JJa"
      },
      "source": [
        "Run the following code only when you connect to Google Drive in the first time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8nMx6285AW9"
      },
      "source": [
        "# %mkdir /content/drive/MyDrive/DL_project\n",
        "# %mkdir /content/drive/MyDrive/DL_project/logs\n",
        "# %mkdir /content/drive/MyDrive/DL_project/models\n",
        "# !git clone https://github.com/facebookresearch/mmf.git\n",
        "# %cp -r /content/mmf /content/drive/MyDrive/DL_project"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLQiKw36w8fK"
      },
      "source": [
        "# Downlad Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXSR03XoxA1Y"
      },
      "source": [
        "url = \"https://drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com/XjiOc5ycDBRRNwbhRlgH.zip?AWSAccessKeyId=AKIARVBOBDCY4MWEDJKS&Signature=vwrcLD1%2FgzoI%2B%2Be4TlMITuWphVg%3D&Expires=1607484815\"\n",
        "password = \"EWryfbZyNviilcDF\"\n",
        "!curl -o ./hm.zip \"$url\" -H 'Referer: https://www.drivendata.org/competitions/64/hateful-memes/data/' --compressed\n",
        "!unzip -qq -P EWryfbZyNviilcDF ./hm.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_IYpdcU5kCU"
      },
      "source": [
        "# Install Required Python Packaget"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSaIDg6SY095",
        "outputId": "6bcff7d6-cf78-47a7-c614-0d901aaed52f"
      },
      "source": [
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html --quiet\n",
        "%cd /content/drive/My Drive/DL_project/mmf\n",
        "!pip install --editable . --quiet\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 708.0MB 25kB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9MB 48.2MB/s \n",
            "\u001b[?25h/content/drive/My Drive/DL_project/mmf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'omegaconf' candidate (version 2.0.1rc4 at https://files.pythonhosted.org/packages/03/c6/dec84d1b2a3d645f03201dca03bc879b6116cb6503449a31d7ff9c1394a4/omegaconf-2.0.1rc4-py3-none-any.whl#sha256=e04462f7e3d8f51532221471b241f67e35a36a04e364c70987018faadd273cc0 (from https://pypi.org/simple/omegaconf/) (requires-python:>=3.6))\n",
            "Reason for being yanked: <none given>\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 870kB 9.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 36.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 53.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 49.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 54.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 61.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 51.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 55.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 54.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.1MB/s \n",
            "\u001b[?25h  Building wheel for lmdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for demjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 4029M  100 4029M    0     0  17.8M      0  0:03:46  0:03:46 --:--:-- 18.0M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpJEzE-S6ay-"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import csv\n",
        "import pandas as pd\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "import torchvision.models\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "\n",
        "from keras_preprocessing.sequence  import pad_sequences\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import accuracy_score, precision_score,recall_score\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRJVUgyx6P1C"
      },
      "source": [
        "## Check if Cuda is enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "3e4da092712d475bb18133c4b682b88e",
            "80cff50a339647debc0d89a7295be80a",
            "51b6cf58b4e34c2bbec8fd6490e20453",
            "350acb580d054ab2ba9da2e0d07f6cdb",
            "40a559d040954fe1b53ac5f55468537a",
            "1ea6438e1a0c495eb40ffc319c1fdee3",
            "d2730342bd424ba0b468f30a3a19eeef",
            "68a4bc9e8f7f404eab11680291511c73",
            "8f9e4fec25a14a83aa312e6cab3d70b6",
            "4f0e7e0ee1e845f08931d9df99f1e3b7",
            "591dedb965294038a6949c229b041355"
          ]
        },
        "id": "n0fisPoFY4g1",
        "outputId": "0cf89f72-948a-414c-aca0-85802b40b06e"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "!nvcc --version\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e4da092712d475bb18133c4b682b88e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5wr5JrF6sqb"
      },
      "source": [
        "# Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OAsEP-BZLK6"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "\n",
        "def read_data(arr, label=False):\n",
        "\n",
        "    df = {}\n",
        "    df[\"id\"] = []\n",
        "    df[\"img_name\"] = []\n",
        "    df[\"text\"] = []\n",
        "\n",
        "    if label:\n",
        "        df[\"label\"] = []\n",
        "\n",
        "    for element in arr:\n",
        "        js = json.loads(element)\n",
        "        df[\"id\"].append(js[\"id\"])\n",
        "        df[\"img_name\"].append(js[\"img\"])\n",
        "        df[\"text\"].append(js[\"text\"])\n",
        "\n",
        "        if label:\n",
        "            df[\"label\"].append(js[\"label\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "class HM_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv, tokenizer, transforms=None, label=False):\n",
        "        self.csv = csv\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transforms = transforms\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.csv)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx.to_list()\n",
        "        req = self.csv.iloc[idx]\n",
        "        img_name = req.img_name\n",
        "        text = req.text\n",
        "        encoding = self.tokenizer.encode(text)\n",
        "        encoding = pad_sequences([encoding], maxlen=20, padding=\"post\")\n",
        "        mask = encoding.copy()\n",
        "        mask[mask > 0] = 1\n",
        "        img = cv2.imread(\"data/\" + img_name)\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        if self.label:\n",
        "            img_label = [req.label]\n",
        "            sample = {\"image\": img, \"label\": torch.FloatTensor(img_label), \"text\": text,\n",
        "                      \"embeddings\": torch.LongTensor(encoding), \"attn\": torch.FloatTensor(mask)}\n",
        "        else:\n",
        "            sample = {\"image\": img, \"text\": text,\n",
        "                      \"embeddings\": torch.LongTensor(encoding), \"attn\": torch.FloatTensor(mask)}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "def preprocess_data(data_file, label=False):\n",
        "\n",
        "    with open(data_file) as f:\n",
        "        arr = f.readlines()\n",
        "\n",
        "    data_dict = read_data(arr, label=label)\n",
        "    dataframe = pd.DataFrame(data_dict)\n",
        "    dataset = HM_Dataset(dataframe, tokenizer, transforms=transform, label=label)\n",
        "    dataloader = DataLoader(dataset, shuffle=True, batch_size=8)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "class CSVLogger():\n",
        "    def __init__(self, filename='log.csv', fieldnames=['epoch']):\n",
        "\n",
        "        self.filename = filename\n",
        "        self.csv_file = open(filename, 'w')\n",
        "\n",
        "        # Write model configuration at top of csv\n",
        "        writer = csv.writer(self.csv_file)\n",
        "\n",
        "        self.writer = csv.DictWriter(self.csv_file, fieldnames=fieldnames)\n",
        "        self.writer.writeheader()\n",
        "\n",
        "        self.csv_file.flush()\n",
        "\n",
        "    def writerow(self, row):\n",
        "        self.writer.writerow(row)\n",
        "        self.csv_file.flush()\n",
        "\n",
        "    def close(self):\n",
        "        self.csv_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rIZyaqI48D1"
      },
      "source": [
        "train_data = preprocess_data(\"data/train.jsonl\", label=True)\n",
        "dev_data = preprocess_data(\"data/dev_seen.jsonl\", label=True)\n",
        "test_data = preprocess_data(\"data/test_seen.jsonl\", label=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_eIubnIpzTy"
      },
      "source": [
        "# Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMrnZQ8rqHpz"
      },
      "source": [
        "The baseline model is from aryamansriram https://github.com/aryamansriram/Hateful_Memes/blob/master/Hateful_Memes.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXpN8aQfZPng"
      },
      "source": [
        "def metrics(out, label, accuracy=True, precision=False, recall=False):\n",
        "    arr = out.detach().cpu().numpy()\n",
        "    mask_0 = arr < 0.5\n",
        "    mask_1 = arr > 0.5\n",
        "    arr[mask_0] = 0\n",
        "    arr[mask_1] = 1\n",
        "    lab = label.cpu().numpy()\n",
        "\n",
        "    ret = []\n",
        "    if accuracy:\n",
        "        acc = np.sum(lab == arr) / len(arr)\n",
        "        ret.append(acc)\n",
        "    if precision:\n",
        "        precision = precision_score(arr, lab)\n",
        "        ret.append(precision)\n",
        "    if recall:\n",
        "        recall = recall_score(arr, lab)\n",
        "        ret.append(recall)\n",
        "    return ret\n",
        "\n",
        "class VGG(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VGG, self).__init__()\n",
        "    torchvision.models.vgg.model_urls['vgg16'] = torchvision.models.vgg.model_urls['vgg16'].replace('https://', 'http://')\n",
        "    vgg = torchvision.models.vgg16(pretrained=True)\n",
        "    self.model = torch.nn.Sequential(*(list(vgg.children())[:-1]))\n",
        "    self.pooling = torch.nn.MaxPool2d(kernel_size=3)\n",
        "    self.flat_layer = nn.Flatten()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.model(x)\n",
        "    x = self.pooling(x)\n",
        "    out = self.flat_layer(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Resnet,self).__init__()\n",
        "    torchvision.models.resnet.model_urls['resnet18'] = torchvision.models.resnet.model_urls['resnet18'].replace('https://', 'http://')\n",
        "    resnet = torchvision.models.resnet18(pretrained=True)\n",
        "    self.model = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
        "    self.pooling = torch.nn.MaxPool2d(kernel_size=3)\n",
        "    self.flat_layer = nn.Flatten()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.model(x)\n",
        "    out = self.flat_layer(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Mobilenet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Mobilenet,self).__init__()\n",
        "    torchvision.models.mobilenet.model_urls['mobilenet_v2'] = torchvision.models.mobilenet.model_urls['mobilenet_v2'].replace('https://', 'http://')\n",
        "    mobilenet = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "    self.model = torch.nn.Sequential(*(list(mobilenet.children())[:-1]))\n",
        "    self.pooling = torch.nn.MaxPool2d(kernel_size=3)\n",
        "    self.flat_layer = nn.Flatten()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.model(x)\n",
        "    x = self.pooling(x)\n",
        "    out = self.flat_layer(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Ensemble(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Ensemble,self).__init__()\n",
        "    self.vgg = VGG()\n",
        "    self.res= Resnet()\n",
        "    self.mobile = Mobilenet()\n",
        "    self.fc_b1 = nn.Sequential(nn.Linear(7680,6000),\n",
        "                               nn.BatchNorm1d(6000))\n",
        "    self.d1 = nn.Dropout(0.6)\n",
        "    self.fc_b2 = nn.Sequential(nn.Linear(6000,3000),\n",
        "                               nn.BatchNorm1d(3000))\n",
        "    self.d2 = nn.Dropout(0.6)\n",
        "    self.fc3 = nn.Linear(3000,768)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x1 = self.vgg(x)\n",
        "    x2 = self.res(x)\n",
        "    x3 = self.mobile(x)\n",
        "    out_1 = torch.cat([x1,x2,x3],dim=1)\n",
        "    out_1 = self.d1(self.fc_b1(out_1))\n",
        "    out_1 = self.d2(self.fc_b2(out_1))\n",
        "    out = self.fc3(out_1)\n",
        "    return out\n",
        "\n",
        "\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.pooling = nn.AvgPool1d(kernel_size=3)\n",
        "        self.flat_layer = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        self.fc3 = nn.Linear(5120, 768)\n",
        "\n",
        "    def forward(self, x, attn):\n",
        "        x = self.model(input_ids=x.squeeze(1), encoder_attention_mask=attn)[0]\n",
        "        x = self.pooling(x)\n",
        "        x = self.flat_layer(x)\n",
        "        out = F.relu(self.fc3(x), inplace=False)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Base_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Base_Model, self).__init__()\n",
        "        self.bert_part = BERT()\n",
        "        self.batch_norm = nn.BatchNorm1d(6000)\n",
        "        self.ensemble = Ensemble()\n",
        "        self.fc1 = nn.Linear(1536, 6000)\n",
        "        self.fc2 = nn.Linear(6000, 3000)\n",
        "        self.fc3 = nn.Linear(3000, 1)\n",
        "\n",
        "    def forward(self, image, text, attn):\n",
        "        x1 = self.ensemble(image)\n",
        "        x2 = self.bert_part(text, attn)\n",
        "\n",
        "        x3 = self.fc1(torch.cat((x1, x2), dim=1))\n",
        "        x3 = self.batch_norm(x3)\n",
        "        x4 = F.relu(self.fc2(x3), inplace=False)\n",
        "        out_1 = self.fc3(x4)\n",
        "        out = torch.sigmoid(out_1)\n",
        "        return out\n",
        "\n",
        "    def fit(self, train_data, valid_data, epochs=3):\n",
        "        losses = []\n",
        "        losses_val = []\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        optim = Adam(self.parameters(), lr=1e-5, weight_decay=0.001)\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "        csv_logger = CSVLogger(filename='/content/drive/My Drive/DL_project/logs/base_model.csv',\n",
        "                       fieldnames=['epoch', 'train_acc', 'test_acc'])\n",
        "        \n",
        "        sm = nn.Softmax(dim=1)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            print(\"===================== Training ====================\")\n",
        "            print(\"Epoch # \", epoch + 1)\n",
        "            train_loss = 0.0\n",
        "            train_acc = 0.0\n",
        "            train_pre = 0.0\n",
        "            train_rec = 0.0\n",
        "\n",
        "            for num, batch in enumerate(train_data):\n",
        "\n",
        "                img, embeddings, label = batch[\"image\"].to(device), batch[\"embeddings\"].to(device), batch[\"label\"].to(\n",
        "                    device)\n",
        "                mask = batch[\"attn\"].to(device)\n",
        "\n",
        "                out = self.forward(img, embeddings, mask)\n",
        "                loss = criterion(out, label)\n",
        "\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "\n",
        "                [acc, prec, rec] = metrics(out, label, accuracy=True, precision=True, recall=True)\n",
        "                \n",
        "                train_loss += loss.item()\n",
        "                train_acc += acc\n",
        "                train_pre += prec\n",
        "                train_rec += rec\n",
        "                \n",
        "\n",
        "                if num > 0 and num % 100 == 0:\n",
        "                    print(\"Loss after \", num, \" steps: \", train_loss / num)\n",
        "                    print(\"Accuracy after \", num, \" steps: \", train_acc / num)\n",
        "\n",
        "            train_loss = train_loss / num\n",
        "            train_acc = train_acc / num\n",
        "            train_pre = train_pre / num\n",
        "            train_rec = train_rec / num\n",
        "\n",
        "            losses.append(train_loss)\n",
        "\n",
        "            print(\"----------------After epoch \", epoch + 1, \"-------------------------\")\n",
        "            print(\"Loss after \", num, \" steps: \", train_loss)\n",
        "            print(\"Accuracy after \", num, \" steps: \", train_acc)\n",
        "\n",
        "            self.eval()\n",
        "            print(\"=====================Validating=====================\")\n",
        "            eval_acc = 0.0\n",
        "            eval_loss = 0.0\n",
        "            eval_prec = 0.0\n",
        "            eval_rec = 0.0\n",
        "\n",
        "            for num,batch in enumerate(valid_data):\n",
        "              img,embeddings,label = batch[\"image\"].to(device),batch[\"embeddings\"].to(device),batch[\"label\"].to(device)\n",
        "              mask = batch[\"attn\"].to(device)\n",
        "              \n",
        "              out = self.forward(img,embeddings,mask)\n",
        "              loss = criterion(out,label)\n",
        "              [acc,precision,recall] = metrics(out,label,True,True,True)\n",
        "              \n",
        "              eval_loss+=loss.item()\n",
        "              eval_acc+=acc\n",
        "              eval_prec+=precision \n",
        "              eval_rec+=recall\n",
        "\n",
        "            valid_data_len = len(valid_data)\n",
        "            eval_loss = eval_loss / valid_data_len\n",
        "            eval_acc = eval_acc / valid_data_len\n",
        "            eval_prec = eval_prec / valid_data_len\n",
        "            eval_rec = eval_rec / valid_data_len\n",
        "\n",
        "            losses_val.append(eval_loss)\n",
        "\n",
        "            print(\"Val_loss after \",epoch+1,\" epochs: \",eval_loss)\n",
        "            print(\"Val_accuracy after \",epoch+1,\" epochs: \",eval_acc)\n",
        "\n",
        "            row = {'epoch': str(epoch+1), 'train_acc': str(train_acc), 'test_acc': str(eval_acc)}\n",
        "            csv_logger.writerow(row)\n",
        "\n",
        "        csv_logger.close()\n",
        "        return losses, losses_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zVe12FhrN3N"
      },
      "source": [
        "Train basline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTkep5gMwzUa"
      },
      "source": [
        "model = Base_Model()\n",
        "model.to(device)\n",
        "num_epochs = 3\n",
        "losses, losses_val = model.fit(train_data, dev_data, epochs=num_epochs)\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/DL_project/models/base_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9LmXteruPB0"
      },
      "source": [
        "# Platt Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqPSrUAlwQm2"
      },
      "source": [
        "def test_calibration(model, data):\n",
        "    model.eval()\n",
        "\n",
        "    probability = []\n",
        "    labels = []\n",
        "\n",
        "    for num,batch in enumerate(data):\n",
        "        img, embeddings, label = batch[\"image\"], batch[\"embeddings\"], batch[\"label\"]\n",
        "        mask = batch[\"attn\"]\n",
        "        prob = model.forward(img, embeddings, mask)\n",
        "        probability.extend(prob.detach().numpy())\n",
        "        labels.extend(label.numpy())\n",
        "        \n",
        "    return probability, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lewaIDYUuRzz"
      },
      "source": [
        "def platt_scaling(p, y):\n",
        "    train_end = int(y.shape[0] / 2)\n",
        "    test_start = train_end + 1\n",
        "\n",
        "    y_train = y[0:train_end]\n",
        "    y_test = y[test_start:]\n",
        "    p_train = p[0:train_end]\n",
        "    p_test = p[test_start:]\n",
        "\n",
        "    lr = LR()\n",
        "    lr.fit(p_train.reshape(-1, 1), y_train)  # LR needs X to be 2-dimensional\n",
        "    p_calibrated = lr.predict_proba(p_test.reshape(-1, 1))[:, 1]\n",
        "\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "\n",
        "    # uncalibrated\n",
        "    mean_predicted_values, true_fractions = calibration_curve(y_test, p_test, n_bins=20)\n",
        "    plt.plot(mean_predicted_values, true_fractions, marker='.', label='before calibration')\n",
        "\n",
        "    # calibrated\n",
        "    mean_predicted_values, true_fractions = calibration_curve(y_test, p_calibrated, n_bins=20)\n",
        "    plt.plot(mean_predicted_values, true_fractions, marker='.', label='after calibration')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.ylabel('fraction of positive')\n",
        "    plt.xlabel('probabilities')\n",
        "\n",
        "    plt.savefig('/content/drive/My Drive/DL_project/calibration.png', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wca-2ubbuVw_"
      },
      "source": [
        "model = Base_Model()\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/DL_project/models/base_model.pt'))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "my_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBvXMHZLwDKY"
      },
      "source": [
        "preds_original, label = test_calibration(model, dev_data)\n",
        "platt_scaling(np.array(preds_original), np.array(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P59UOY5arr4D"
      },
      "source": [
        "# Add Confidence Estimate Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAI3GrFqr68M"
      },
      "source": [
        "The idea is from Terrance DeVries, Graham W. Taylor in \"Learning Confidence for Out-of-Distribution Detection in Neural Networks\" https://arxiv.org/abs/1802.04865"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSljxGnKYNzc"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import seaborn as sns\n",
        "\n",
        "def metrics2(out, label, accuracy=True, precision=False, recall=False):\n",
        "    arr = out.detach().cpu().numpy()\n",
        "    lab = label.cpu().numpy()\n",
        "\n",
        "    pred = np.zeros_like(lab)\n",
        "    for i, a in enumerate(arr):\n",
        "        if a[0] < a[1]:\n",
        "            pred[i] = 1\n",
        "\n",
        "    ret = []\n",
        "    if accuracy:\n",
        "        acc = np.sum(lab == pred) / len(pred)\n",
        "        ret.append(acc)\n",
        "    if precision:\n",
        "        precision = precision_score(pred, lab)\n",
        "        ret.append(precision)\n",
        "    if recall:\n",
        "        recall = recall_score(pred, lab)\n",
        "        ret.append(recall)\n",
        "    return ret\n",
        "\n",
        "\n",
        "class My_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(My_Model, self).__init__()\n",
        "        self.bert_part = BERT()\n",
        "        self.batch_norm = nn.BatchNorm1d(6000)\n",
        "        self.ensemble = Ensemble()\n",
        "\n",
        "        self.confidence = nn.Linear(1536, 1) # confidence layer\n",
        "        self.fc1 = nn.Linear(1536, 6000)\n",
        "        self.fc2 = nn.Linear(6000, 3000)\n",
        "        self.fc3 = nn.Linear(3000, 1)\n",
        "\n",
        "    def forward(self, image, text, attn):\n",
        "        x1 = self.ensemble(image)\n",
        "        x2 = self.bert_part(text, attn)\n",
        "        out = torch.cat((x1, x2), dim=1)\n",
        "        c = torch.sigmoid(self.confidence(out)) # the location of confidence layer is after the merge\n",
        "\n",
        "        x3 = self.fc1(out)\n",
        "        x3 = self.batch_norm(x3)\n",
        "        x4 = F.relu(self.fc2(x3), inplace=False)\n",
        "        pred = torch.sigmoid(self.fc3(x4))\n",
        "        return pred, c\n",
        "\n",
        "    def fit(self, train_data, valid_data, budget=0.3, epochs=3):\n",
        "        losses = []\n",
        "        losses_val = []\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        optim = Adam(self.parameters(), lr=1e-5, weight_decay=0.001)\n",
        "        criterion = nn.BCELoss()\n",
        "        lmbda = 0.1\n",
        "        eps = 1e-12\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            print(\"===================== Training ====================\")\n",
        "            print(\"Epoch # \", epoch + 1)\n",
        "            train_loss = 0.0\n",
        "            train_acc = 0.0\n",
        "            train_pre = 0.0\n",
        "            train_rec = 0.0\n",
        "\n",
        "            for num, batch in enumerate(train_data):\n",
        "                img, embeddings, label = batch[\"image\"].to(device), batch[\"embeddings\"].to(device), batch[\"label\"].to(\n",
        "                    device)\n",
        "                mask = batch[\"attn\"].to(device)\n",
        "\n",
        "                out, c = self.forward(img, embeddings, mask)\n",
        "\n",
        "                out = torch.clamp(out, 0. + eps, 1. - eps)\n",
        "                c = torch.clamp(c, 0. + eps, 1. - eps)\n",
        "\n",
        "                b = Variable(torch.bernoulli(torch.Tensor(c.size()).uniform_(0, 1))).to(device)\n",
        "                confidence = c * b + (1 - b)\n",
        "                pred_new = out * confidence.expand_as(out) + label * (1 - confidence.expand_as(label))\n",
        "                \n",
        "                xentropy_loss = criterion(pred_new, label)\n",
        "                confidence_loss = torch.mean(-torch.log(c))\n",
        "                total_loss = xentropy_loss + lmbda * confidence_loss\n",
        "\n",
        "                if budget > confidence_loss.item():\n",
        "                    lmbda = lmbda / 1.01\n",
        "                elif budget <= confidence_loss.item():\n",
        "                    lmbda = lmbda / 0.99\n",
        "\n",
        "                train_loss += total_loss\n",
        "\n",
        "                [acc, prec, rec] = metrics(out, label, accuracy=True, precision=True, recall=True)\n",
        "                train_acc += acc\n",
        "                train_pre += prec\n",
        "                train_rec += rec\n",
        "\n",
        "                total_loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "\n",
        "                if num > 0 and num % 100 == 0:\n",
        "                    print(\"Loss after \", num, \" steps: \", train_loss / num)\n",
        "                    print(\"Accuracy after \", num, \" steps: \", train_acc / num)\n",
        "\n",
        "            train_loss = train_loss / num\n",
        "            train_acc = train_acc / num\n",
        "            train_pre = train_pre / num\n",
        "            train_rec = train_rec / num\n",
        "\n",
        "            losses.append(train_loss)\n",
        "\n",
        "            print(\"----------------After epoch \", epoch + 1, \"-------------------------\")\n",
        "            print(\"Loss after \", num, \" steps: \", train_loss)\n",
        "            print(\"Accuracy after \", num, \" steps: \", train_acc)\n",
        "\n",
        "        csv_logger.close()\n",
        "        return losses, losses_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7x4CPUus8CI"
      },
      "source": [
        "Train confidence estimate layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRpm5eyyY6bl",
        "outputId": "9bf38139-68bc-4d41-cddb-58ef3449b7d2"
      },
      "source": [
        "my_model = My_Model()\n",
        "my_model.to(device)\n",
        "\n",
        "num_epochs = 3\n",
        "losses, losses_val = my_model.fit(train_data, dev_data, budget=0.3, epochs=num_epochs)\n",
        "torch.save(my_model.state_dict(), '/content/drive/My Drive/DL_project/models/my_model.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===================== Training ====================\n",
            "Epoch #  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss after  100  steps:  tensor(0.6054, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  100  steps:  0.5925\n",
            "Precision after  100  steps:  0.32666666666666666\n",
            "Recall after  100  steps:  0.3883333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss after  200  steps:  tensor(0.6345, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  200  steps:  0.58625\n",
            "Precision after  200  steps:  0.31125000000000014\n",
            "Recall after  200  steps:  0.4154166666666667\n",
            "Loss after  300  steps:  tensor(0.6279, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  300  steps:  0.60625\n",
            "Precision after  300  steps:  0.31766666666666665\n",
            "Recall after  300  steps:  0.4341666666666666\n",
            "Loss after  400  steps:  tensor(0.6115, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  400  steps:  0.62875\n",
            "Precision after  400  steps:  0.3554999999999998\n",
            "Recall after  400  steps:  0.4775\n",
            "Loss after  500  steps:  tensor(0.5961, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  500  steps:  0.647\n",
            "Precision after  500  steps:  0.3738904761904763\n",
            "Recall after  500  steps:  0.49816666666666665\n",
            "Loss after  600  steps:  tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  600  steps:  0.6585416666666667\n",
            "Precision after  600  steps:  0.3981230158730159\n",
            "Recall after  600  steps:  0.5211111111111112\n",
            "Loss after  700  steps:  tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  700  steps:  0.6683928571428571\n",
            "Precision after  700  steps:  0.4052312925170068\n",
            "Recall after  700  steps:  0.5330952380952382\n",
            "Loss after  800  steps:  tensor(0.5723, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  800  steps:  0.675\n",
            "Precision after  800  steps:  0.41674702380952383\n",
            "Recall after  800  steps:  0.5483333333333335\n",
            "Loss after  900  steps:  tensor(0.5668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  900  steps:  0.6822222222222222\n",
            "Precision after  900  steps:  0.4254603174603175\n",
            "Recall after  900  steps:  0.5520370370370372\n",
            "Loss after  1000  steps:  tensor(0.5640, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1000  steps:  0.686125\n",
            "Precision after  1000  steps:  0.42833095238095215\n",
            "Recall after  1000  steps:  0.5608333333333333\n",
            "----------------After epoch  1 -------------------------\n",
            "Loss after  1062  steps:  tensor(0.5624, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1062  steps:  0.687617702448211\n",
            "Precision after  1062  steps:  0.43044569993722515\n",
            "Recall after  1062  steps:  0.5679535467671061\n",
            "===================== Training ====================\n",
            "Epoch #  2\n",
            "Loss after  100  steps:  tensor(0.4470, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  100  steps:  0.79\n",
            "Precision after  100  steps:  0.6268333333333332\n",
            "Recall after  100  steps:  0.7066666666666666\n",
            "Loss after  200  steps:  tensor(0.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  200  steps:  0.778125\n",
            "Precision after  200  steps:  0.6393452380952384\n",
            "Recall after  200  steps:  0.7291666666666665\n",
            "Loss after  300  steps:  tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  300  steps:  0.7770833333333333\n",
            "Precision after  300  steps:  0.6355714285714285\n",
            "Recall after  300  steps:  0.7313888888888885\n",
            "Loss after  400  steps:  tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  400  steps:  0.78\n",
            "Precision after  400  steps:  0.633053571428571\n",
            "Recall after  400  steps:  0.7293749999999999\n",
            "Loss after  500  steps:  tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  500  steps:  0.7785\n",
            "Precision after  500  steps:  0.6250428571428569\n",
            "Recall after  500  steps:  0.7193333333333333\n",
            "Loss after  600  steps:  tensor(0.4510, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  600  steps:  0.7783333333333333\n",
            "Precision after  600  steps:  0.629924603174603\n",
            "Recall after  600  steps:  0.7212222222222224\n",
            "Loss after  700  steps:  tensor(0.4560, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  700  steps:  0.7767857142857143\n",
            "Precision after  700  steps:  0.6359353741496595\n",
            "Recall after  700  steps:  0.7260000000000004\n",
            "Loss after  800  steps:  tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  800  steps:  0.7765625\n",
            "Precision after  800  steps:  0.632297619047619\n",
            "Recall after  800  steps:  0.725354166666667\n",
            "Loss after  900  steps:  tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  900  steps:  0.7748611111111111\n",
            "Precision after  900  steps:  0.6290793650793651\n",
            "Recall after  900  steps:  0.7215370370370373\n",
            "Loss after  1000  steps:  tensor(0.4542, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1000  steps:  0.7755\n",
            "Precision after  1000  steps:  0.6262380952380951\n",
            "Recall after  1000  steps:  0.7221333333333334\n",
            "----------------After epoch  2 -------------------------\n",
            "Loss after  1062  steps:  tensor(0.4535, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1062  steps:  0.775894538606403\n",
            "Precision after  1062  steps:  0.6246906107075596\n",
            "Recall after  1062  steps:  0.7207784055241684\n",
            "===================== Training ====================\n",
            "Epoch #  3\n",
            "Loss after  100  steps:  tensor(0.3605, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  100  steps:  0.81875\n",
            "Precision after  100  steps:  0.6716666666666665\n",
            "Recall after  100  steps:  0.8108333333333333\n",
            "Loss after  200  steps:  tensor(0.3532, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  200  steps:  0.818125\n",
            "Precision after  200  steps:  0.6899761904761906\n",
            "Recall after  200  steps:  0.7946666666666666\n",
            "Loss after  300  steps:  tensor(0.3498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  300  steps:  0.8183333333333334\n",
            "Precision after  300  steps:  0.7063650793650793\n",
            "Recall after  300  steps:  0.7936666666666664\n",
            "Loss after  400  steps:  tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  400  steps:  0.8190625\n",
            "Precision after  400  steps:  0.7121369047619049\n",
            "Recall after  400  steps:  0.7958750000000001\n",
            "Loss after  500  steps:  tensor(0.3615, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  500  steps:  0.821\n",
            "Precision after  500  steps:  0.7166000000000009\n",
            "Recall after  500  steps:  0.7884666666666672\n",
            "Loss after  600  steps:  tensor(0.3621, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  600  steps:  0.8183333333333334\n",
            "Precision after  600  steps:  0.7129722222222233\n",
            "Recall after  600  steps:  0.7769166666666674\n",
            "Loss after  700  steps:  tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  700  steps:  0.8192857142857143\n",
            "Precision after  700  steps:  0.7083095238095253\n",
            "Recall after  700  steps:  0.7788571428571436\n",
            "Loss after  800  steps:  tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  800  steps:  0.81875\n",
            "Precision after  800  steps:  0.7042232142857151\n",
            "Recall after  800  steps:  0.7742083333333334\n",
            "Loss after  900  steps:  tensor(0.3679, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  900  steps:  0.8166666666666667\n",
            "Precision after  900  steps:  0.7016084656084657\n",
            "Recall after  900  steps:  0.7739259259259257\n",
            "Loss after  1000  steps:  tensor(0.3739, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1000  steps:  0.814375\n",
            "Precision after  1000  steps:  0.6933976190476189\n",
            "Recall after  1000  steps:  0.7716666666666661\n",
            "----------------After epoch  3 -------------------------\n",
            "Loss after  1062  steps:  tensor(0.3764, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1062  steps:  0.8134416195856874\n",
            "Precision after  1062  steps:  0.690911129046722\n",
            "Recall after  1062  steps:  0.7679692404268668\n",
            "===================== Training ====================\n",
            "Epoch #  4\n",
            "Loss after  100  steps:  tensor(0.3074, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  100  steps:  0.87375\n",
            "Precision after  100  steps:  0.7953809523809525\n",
            "Recall after  100  steps:  0.8383333333333334\n",
            "Loss after  200  steps:  tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  200  steps:  0.865\n",
            "Precision after  200  steps:  0.7946071428571428\n",
            "Recall after  200  steps:  0.8300833333333334\n",
            "Loss after  300  steps:  tensor(0.3074, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  300  steps:  0.8525\n",
            "Precision after  300  steps:  0.7863968253968252\n",
            "Recall after  300  steps:  0.8170555555555552\n",
            "Loss after  400  steps:  tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  400  steps:  0.8596875\n",
            "Precision after  400  steps:  0.7967559523809525\n",
            "Recall after  400  steps:  0.8127916666666664\n",
            "Loss after  500  steps:  tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  500  steps:  0.8585\n",
            "Precision after  500  steps:  0.795771428571429\n",
            "Recall after  500  steps:  0.8079000000000002\n",
            "Loss after  600  steps:  tensor(0.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  600  steps:  0.8585416666666666\n",
            "Precision after  600  steps:  0.7960515873015883\n",
            "Recall after  600  steps:  0.8108888888888894\n",
            "Loss after  700  steps:  tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  700  steps:  0.8558928571428571\n",
            "Precision after  700  steps:  0.7891224489795926\n",
            "Recall after  700  steps:  0.8042857142857148\n",
            "Loss after  800  steps:  tensor(0.3051, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  800  steps:  0.85421875\n",
            "Precision after  800  steps:  0.7800059523809522\n",
            "Recall after  800  steps:  0.8018124999999999\n",
            "Loss after  900  steps:  tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  900  steps:  0.8570833333333333\n",
            "Precision after  900  steps:  0.7822169312169303\n",
            "Recall after  900  steps:  0.8027222222222217\n",
            "Loss after  1000  steps:  tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1000  steps:  0.857625\n",
            "Precision after  1000  steps:  0.7799714285714271\n",
            "Recall after  1000  steps:  0.8029666666666657\n",
            "----------------After epoch  4 -------------------------\n",
            "Loss after  1062  steps:  tensor(0.3008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1062  steps:  0.8585216572504708\n",
            "Precision after  1062  steps:  0.7806855887364345\n",
            "Recall after  1062  steps:  0.8038449466415557\n",
            "===================== Training ====================\n",
            "Epoch #  5\n",
            "Loss after  100  steps:  tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  100  steps:  0.90625\n",
            "Precision after  100  steps:  0.8421666666666667\n",
            "Recall after  100  steps:  0.8533333333333332\n",
            "Loss after  200  steps:  tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  200  steps:  0.900625\n",
            "Precision after  200  steps:  0.8399999999999999\n",
            "Recall after  200  steps:  0.8448333333333332\n",
            "Loss after  300  steps:  tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  300  steps:  0.8983333333333333\n",
            "Precision after  300  steps:  0.8488809523809524\n",
            "Recall after  300  steps:  0.8456111111111105\n",
            "Loss after  400  steps:  tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  400  steps:  0.898125\n",
            "Precision after  400  steps:  0.8559285714285717\n",
            "Recall after  400  steps:  0.8398749999999998\n",
            "Loss after  500  steps:  tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  500  steps:  0.8985\n",
            "Precision after  500  steps:  0.8531428571428578\n",
            "Recall after  500  steps:  0.8407333333333334\n",
            "Loss after  600  steps:  tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  600  steps:  0.8966666666666666\n",
            "Precision after  600  steps:  0.8530912698412708\n",
            "Recall after  600  steps:  0.8482500000000005\n",
            "Loss after  700  steps:  tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  700  steps:  0.8976785714285714\n",
            "Precision after  700  steps:  0.8577687074829932\n",
            "Recall after  700  steps:  0.8522619047619047\n",
            "Loss after  800  steps:  tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  800  steps:  0.8965625\n",
            "Precision after  800  steps:  0.8578392857142849\n",
            "Recall after  800  steps:  0.8504791666666659\n",
            "Loss after  900  steps:  tensor(0.2239, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  900  steps:  0.8966666666666666\n",
            "Precision after  900  steps:  0.8561111111111099\n",
            "Recall after  900  steps:  0.8515555555555546\n",
            "Loss after  1000  steps:  tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1000  steps:  0.89625\n",
            "Precision after  1000  steps:  0.8567119047619035\n",
            "Recall after  1000  steps:  0.8531166666666656\n",
            "----------------After epoch  5 -------------------------\n",
            "Loss after  1062  steps:  tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1062  steps:  0.8934792843691148\n",
            "Precision after  1062  steps:  0.8503250829522001\n",
            "Recall after  1062  steps:  0.8520558694287498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v8iryMstXJ0"
      },
      "source": [
        "Plot the confidence Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym7rdbxDz5g3"
      },
      "source": [
        "my_model = My_Model()\n",
        "my_model.load_state_dict(torch.load('/content/drive/My Drive/DL_project/models/my_model.pt'))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "my_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9fcgcelY6OP"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "\n",
        "def plot_histograms(conf_1, conf_2, out_type = 'Confidence', bins=100, norm_hist=True):\n",
        "    global conf_histogram\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.distplot(conf_1, kde=False, bins=bins, norm_hist=norm_hist, label='Train Data')\n",
        "    sns.distplot(conf_2, kde=False, bins=bins, norm_hist=norm_hist, label='Test Data')\n",
        "    \n",
        "    plt.xlabel(out_type)\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/content/drive/My Drive/DL_project/\" + out_type + \"_histogram.png\")\n",
        "\n",
        "\n",
        "def test_confidence(model, data):\n",
        "\n",
        "    model.eval()\n",
        "    confidence = []\n",
        "\n",
        "    for num,batch in enumerate(data):\n",
        "      img,embeddings= batch[\"image\"].to(device),batch[\"embeddings\"].to(device)\n",
        "      mask = batch[\"attn\"].to(device)\n",
        "      out, conf = model.forward(img,embeddings,mask)\n",
        "      confidence.extend(conf.detach().cpu().numpy())\n",
        "    \n",
        "    confidence = np.array(confidence)\n",
        "\n",
        "    return confidence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxbYeap0DCrr"
      },
      "source": [
        "train_data = preprocess_data(\"data/train.jsonl\", label=True)\n",
        "conf_1 = test_confidence(my_model, train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPSjrp0XC_Kf"
      },
      "source": [
        "test_data = preprocess_data(\"data/dev_unseen.jsonl\", label=False)\n",
        "conf_2 = test_confidence(my_model, test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "hMclDvQf7FaC",
        "outputId": "f6243111-b065-4bdd-d2b0-21b8e6ef07c2"
      },
      "source": [
        "plot_histograms(conf_1, conf_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}