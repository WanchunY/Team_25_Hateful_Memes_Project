{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Measuring Model Confidence",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO8wy/raUWspRsS4IlrrL7+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df67b4eeb04a44769624f418ccca97d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d55e7b17d0814928bc92af46d635e231",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_849b398c974840b7966f1c26ae70c002",
              "IPY_MODEL_3afe246ab36b4150ab2cdabf60c723d8",
              "IPY_MODEL_a7b5fc184e4640b99f9c60bb02631ee0"
            ]
          }
        },
        "d55e7b17d0814928bc92af46d635e231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "849b398c974840b7966f1c26ae70c002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c18c9c2892da4d40bcf972e2468dfb60",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c0e3416f424412ca4c5c3ecd61d6285"
          }
        },
        "3afe246ab36b4150ab2cdabf60c723d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5dc229f6fa1a47edaa360ba340e58860",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65202fc10eb4464e82490fee5a312786"
          }
        },
        "a7b5fc184e4640b99f9c60bb02631ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_60c3fe22ae40419389450b823e836759",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:25&lt;00:00, 9.02kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42a93c4df45c41f1a8473dcadaf964d2"
          }
        },
        "c18c9c2892da4d40bcf972e2468dfb60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c0e3416f424412ca4c5c3ecd61d6285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5dc229f6fa1a47edaa360ba340e58860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65202fc10eb4464e82490fee5a312786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60c3fe22ae40419389450b823e836759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42a93c4df45c41f1a8473dcadaf964d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shenxinspeed/Team_25_Hatefull_Memes_Project/blob/main/Measuring_Model_Confidence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5CkcBoY4jrZ"
      },
      "source": [
        "# Connect to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egyinOj_4xzR"
      },
      "source": [
        "The google drive is used to store trained models, training results and analysis plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpai0lGoS9N2",
        "outputId": "a6ab8f7a-5622-42db-cce4-b262cf4e2a8e"
      },
      "source": [
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuYyCa8W5AEn"
      },
      "source": [
        "## Create Folders on Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfysDmFS5JJa"
      },
      "source": [
        "Run the following code only when you connect to Google Drive in the first time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8nMx6285AW9"
      },
      "source": [
        "# %mkdir /content/drive/MyDrive/DL_project\n",
        "# %mkdir /content/drive/MyDrive/DL_project/logs\n",
        "# %mkdir /content/drive/MyDrive/DL_project/models\n",
        "# !git clone https://github.com/facebookresearch/mmf.git\n",
        "# %cp -r /content/mmf /content/drive/MyDrive/DL_project"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLQiKw36w8fK"
      },
      "source": [
        "# Downlad Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXSR03XoxA1Y",
        "outputId": "ba6504cc-a01f-4bfb-8f90-4f4e8a5829cb"
      },
      "source": [
        "url = \"https://drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com/XjiOc5ycDBRRNwbhRlgH.zip?AWSAccessKeyId=AKIARVBOBDCY4MWEDJKS&Signature=vwrcLD1%2FgzoI%2B%2Be4TlMITuWphVg%3D&Expires=1607484815\"\n",
        "password = \"EWryfbZyNviilcDF\"\n",
        "!curl -o ./hm.zip \"$url\" -H 'Referer: https://www.drivendata.org/competitions/64/hateful-memes/data/' --compressed\n",
        "!unzip -qq -P EWryfbZyNviilcDF ./hm.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 4029M  100 4029M    0     0  18.3M      0  0:03:40  0:03:40 --:--:-- 18.6M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_IYpdcU5kCU"
      },
      "source": [
        "# Install Required Python Packaget"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSaIDg6SY095",
        "outputId": "5f3eccd8-4a23-4948-ae4d-b7c5ed33106e"
      },
      "source": [
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html --quiet\n",
        "%cd /content/drive/My Drive/DL_project/mmf\n",
        "!pip install --editable . --quiet\n",
        "%cd /content"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 708.0MB 20kB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9MB 75.9MB/s \n",
            "\u001b[?25h/content/drive/My Drive/DL_project/mmf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 18.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 55.6MB/s \n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'omegaconf' candidate (version 2.0.1rc4 at https://files.pythonhosted.org/packages/03/c6/dec84d1b2a3d645f03201dca03bc879b6116cb6503449a31d7ff9c1394a4/omegaconf-2.0.1rc4-py3-none-any.whl#sha256=e04462f7e3d8f51532221471b241f67e35a36a04e364c70987018faadd273cc0 (from https://pypi.org/simple/omegaconf/) (requires-python:>=3.6))\n",
            "Reason for being yanked: <none given>\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 133kB 60.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 54.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 62.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 57.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 57.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 50.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.2MB/s \n",
            "\u001b[?25h  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for demjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lmdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpJEzE-S6ay-"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import csv\n",
        "import pandas as pd\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "import torchvision.models\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "\n",
        "from keras_preprocessing.sequence  import pad_sequences\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import accuracy_score, precision_score,recall_score\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRJVUgyx6P1C"
      },
      "source": [
        "## Check if Cuda is enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0fisPoFY4g1",
        "outputId": "14d98e9a-1ebb-4c4d-87a5-e9b4e2bf6b20"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "!nvcc --version\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5wr5JrF6sqb"
      },
      "source": [
        "# Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OAsEP-BZLK6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "df67b4eeb04a44769624f418ccca97d0",
            "d55e7b17d0814928bc92af46d635e231",
            "849b398c974840b7966f1c26ae70c002",
            "3afe246ab36b4150ab2cdabf60c723d8",
            "a7b5fc184e4640b99f9c60bb02631ee0",
            "c18c9c2892da4d40bcf972e2468dfb60",
            "9c0e3416f424412ca4c5c3ecd61d6285",
            "5dc229f6fa1a47edaa360ba340e58860",
            "65202fc10eb4464e82490fee5a312786",
            "60c3fe22ae40419389450b823e836759",
            "42a93c4df45c41f1a8473dcadaf964d2"
          ]
        },
        "outputId": "f8b59e7d-f800-4c75-d7e3-51d062435bc2"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "\n",
        "def read_data(arr, label=False):\n",
        "\n",
        "    df = {}\n",
        "    df[\"id\"] = []\n",
        "    df[\"img_name\"] = []\n",
        "    df[\"text\"] = []\n",
        "\n",
        "    if label:\n",
        "        df[\"label\"] = []\n",
        "\n",
        "    for element in arr:\n",
        "        js = json.loads(element)\n",
        "        df[\"id\"].append(js[\"id\"])\n",
        "        df[\"img_name\"].append(js[\"img\"])\n",
        "        df[\"text\"].append(js[\"text\"])\n",
        "\n",
        "        if label:\n",
        "            df[\"label\"].append(js[\"label\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "class HM_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv, tokenizer, transforms=None, label=False):\n",
        "        self.csv = csv\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transforms = transforms\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.csv)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx.to_list()\n",
        "        req = self.csv.iloc[idx]\n",
        "        img_name = req.img_name\n",
        "        text = req.text\n",
        "        encoding = self.tokenizer.encode(text)\n",
        "        encoding = pad_sequences([encoding], maxlen=20, padding=\"post\")\n",
        "        mask = encoding.copy()\n",
        "        mask[mask > 0] = 1\n",
        "        img = cv2.imread(\"data/\" + img_name)\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        if self.label:\n",
        "            img_label = [req.label]\n",
        "            sample = {\"image\": img, \"label\": torch.FloatTensor(img_label), \"text\": text,\n",
        "                      \"embeddings\": torch.LongTensor(encoding), \"attn\": torch.FloatTensor(mask)}\n",
        "        else:\n",
        "            sample = {\"image\": img, \"text\": text,\n",
        "                      \"embeddings\": torch.LongTensor(encoding), \"attn\": torch.FloatTensor(mask)}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "def preprocess_data(data_file, label=False):\n",
        "\n",
        "    with open(data_file) as f:\n",
        "        arr = f.readlines()\n",
        "\n",
        "    data_dict = read_data(arr, label=label)\n",
        "    dataframe = pd.DataFrame(data_dict)\n",
        "    dataset = HM_Dataset(dataframe, tokenizer, transforms=transform, label=label)\n",
        "    dataloader = DataLoader(dataset, shuffle=True, batch_size=8)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "class CSVLogger():\n",
        "    def __init__(self, filename='log.csv', fieldnames=['epoch']):\n",
        "\n",
        "        self.filename = filename\n",
        "        self.csv_file = open(filename, 'w')\n",
        "\n",
        "        # Write model configuration at top of csv\n",
        "        writer = csv.writer(self.csv_file)\n",
        "\n",
        "        self.writer = csv.DictWriter(self.csv_file, fieldnames=fieldnames)\n",
        "        self.writer.writeheader()\n",
        "\n",
        "        self.csv_file.flush()\n",
        "\n",
        "    def writerow(self, row):\n",
        "        self.writer.writerow(row)\n",
        "        self.csv_file.flush()\n",
        "\n",
        "    def close(self):\n",
        "        self.csv_file.close()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df67b4eeb04a44769624f418ccca97d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rIZyaqI48D1"
      },
      "source": [
        "train_data = preprocess_data(\"data/train.jsonl\", label=True)\n",
        "dev_data = preprocess_data(\"data/dev_seen.jsonl\", label=True)\n",
        "test_data = preprocess_data(\"data/test_seen.jsonl\", label=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_eIubnIpzTy"
      },
      "source": [
        "# Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMrnZQ8rqHpz"
      },
      "source": [
        "The baseline model is from aryamansriram https://github.com/aryamansriram/Hateful_Memes/blob/master/Hateful_Memes.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXpN8aQfZPng"
      },
      "source": [
        "def metrics(out, label, accuracy=True, precision=False, recall=False):\n",
        "    arr = out.detach().cpu().numpy()\n",
        "    mask_0 = arr < 0.5\n",
        "    mask_1 = arr > 0.5\n",
        "    arr[mask_0] = 0\n",
        "    arr[mask_1] = 1\n",
        "    lab = label.cpu().numpy()\n",
        "\n",
        "    ret = []\n",
        "    if accuracy:\n",
        "        acc = np.sum(lab == arr) / len(arr)\n",
        "        ret.append(acc)\n",
        "    if precision:\n",
        "        precision = precision_score(arr, lab)\n",
        "        ret.append(precision)\n",
        "    if recall:\n",
        "        recall = recall_score(arr, lab)\n",
        "        ret.append(recall)\n",
        "    return ret\n",
        "\n",
        "class VGG(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VGG, self).__init__()\n",
        "    torchvision.models.vgg.model_urls['vgg16'] = torchvision.models.vgg.model_urls['vgg16'].replace('https://', 'http://')\n",
        "    vgg = torchvision.models.vgg16(pretrained=True)\n",
        "    self.model = torch.nn.Sequential(*(list(vgg.children())[:-1]))\n",
        "    self.pooling = torch.nn.MaxPool2d(kernel_size=3)\n",
        "    self.flat_layer = nn.Flatten()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.model(x)\n",
        "    x = self.pooling(x)\n",
        "    out = self.flat_layer(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Resnet,self).__init__()\n",
        "    torchvision.models.resnet.model_urls['resnet18'] = torchvision.models.resnet.model_urls['resnet18'].replace('https://', 'http://')\n",
        "    resnet = torchvision.models.resnet18(pretrained=True)\n",
        "    self.model = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
        "    self.pooling = torch.nn.MaxPool2d(kernel_size=3)\n",
        "    self.flat_layer = nn.Flatten()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.model(x)\n",
        "    out = self.flat_layer(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Mobilenet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Mobilenet,self).__init__()\n",
        "    torchvision.models.mobilenet.model_urls['mobilenet_v2'] = torchvision.models.mobilenet.model_urls['mobilenet_v2'].replace('https://', 'http://')\n",
        "    mobilenet = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "    self.model = torch.nn.Sequential(*(list(mobilenet.children())[:-1]))\n",
        "    self.pooling = torch.nn.MaxPool2d(kernel_size=3)\n",
        "    self.flat_layer = nn.Flatten()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.model(x)\n",
        "    x = self.pooling(x)\n",
        "    out = self.flat_layer(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Ensemble(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Ensemble,self).__init__()\n",
        "    self.vgg = VGG()\n",
        "    self.res= Resnet()\n",
        "    self.mobile = Mobilenet()\n",
        "    self.fc_b1 = nn.Sequential(nn.Linear(7680,6000),\n",
        "                               nn.BatchNorm1d(6000))\n",
        "    self.d1 = nn.Dropout(0.6)\n",
        "    self.fc_b2 = nn.Sequential(nn.Linear(6000,3000),\n",
        "                               nn.BatchNorm1d(3000))\n",
        "    self.d2 = nn.Dropout(0.6)\n",
        "    self.fc3 = nn.Linear(3000,768)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x1 = self.vgg(x)\n",
        "    x2 = self.res(x)\n",
        "    x3 = self.mobile(x)\n",
        "    out_1 = torch.cat([x1,x2,x3],dim=1)\n",
        "    out_1 = self.d1(self.fc_b1(out_1))\n",
        "    out_1 = self.d2(self.fc_b2(out_1))\n",
        "    out = self.fc3(out_1)\n",
        "    return out\n",
        "\n",
        "\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.pooling = nn.AvgPool1d(kernel_size=3)\n",
        "        self.flat_layer = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        self.fc3 = nn.Linear(5120, 768)\n",
        "\n",
        "    def forward(self, x, attn):\n",
        "        x = self.model(input_ids=x.squeeze(1), encoder_attention_mask=attn)[0]\n",
        "        x = self.pooling(x)\n",
        "        x = self.flat_layer(x)\n",
        "        out = F.relu(self.fc3(x), inplace=False)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Base_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Base_Model, self).__init__()\n",
        "        self.bert_part = BERT()\n",
        "        self.batch_norm = nn.BatchNorm1d(6000)\n",
        "        self.ensemble = Ensemble()\n",
        "        self.fc1 = nn.Linear(1536, 6000)\n",
        "        self.fc2 = nn.Linear(6000, 3000)\n",
        "        self.fc3 = nn.Linear(3000, 1)\n",
        "\n",
        "    def forward(self, image, text, attn):\n",
        "        x1 = self.ensemble(image)\n",
        "        x2 = self.bert_part(text, attn)\n",
        "\n",
        "        x3 = self.fc1(torch.cat((x1, x2), dim=1))\n",
        "        x3 = self.batch_norm(x3)\n",
        "        x4 = F.relu(self.fc2(x3), inplace=False)\n",
        "        out_1 = self.fc3(x4)\n",
        "        out = torch.sigmoid(out_1)\n",
        "        return out\n",
        "\n",
        "    def fit(self, train_data, valid_data, epochs=3):\n",
        "        losses = []\n",
        "        losses_val = []\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        optim = Adam(self.parameters(), lr=1e-5, weight_decay=0.001)\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "        csv_logger = CSVLogger(filename='/content/drive/My Drive/DL_project/logs/base_model.csv',\n",
        "                       fieldnames=['epoch', 'train_acc', 'test_acc'])\n",
        "        \n",
        "        sm = nn.Softmax(dim=1)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            print(\"===================== Training ====================\")\n",
        "            print(\"Epoch # \", epoch + 1)\n",
        "            train_loss = 0.0\n",
        "            train_acc = 0.0\n",
        "            train_pre = 0.0\n",
        "            train_rec = 0.0\n",
        "\n",
        "            for num, batch in enumerate(train_data):\n",
        "\n",
        "                img, embeddings, label = batch[\"image\"].to(device), batch[\"embeddings\"].to(device), batch[\"label\"].to(\n",
        "                    device)\n",
        "                mask = batch[\"attn\"].to(device)\n",
        "\n",
        "                out = self.forward(img, embeddings, mask)\n",
        "                loss = criterion(out, label)\n",
        "\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "\n",
        "                [acc, prec, rec] = metrics(out, label, accuracy=True, precision=True, recall=True)\n",
        "                \n",
        "                train_loss += loss.item()\n",
        "                train_acc += acc\n",
        "                train_pre += prec\n",
        "                train_rec += rec\n",
        "                \n",
        "\n",
        "                if num > 0 and num % 100 == 0:\n",
        "                    print(\"Loss after \", num, \" steps: \", train_loss / num)\n",
        "                    print(\"Accuracy after \", num, \" steps: \", train_acc / num)\n",
        "\n",
        "            train_loss = train_loss / num\n",
        "            train_acc = train_acc / num\n",
        "            train_pre = train_pre / num\n",
        "            train_rec = train_rec / num\n",
        "\n",
        "            losses.append(train_loss)\n",
        "\n",
        "            print(\"----------------After epoch \", epoch + 1, \"-------------------------\")\n",
        "            print(\"Loss after \", num, \" steps: \", train_loss)\n",
        "            print(\"Accuracy after \", num, \" steps: \", train_acc)\n",
        "\n",
        "            self.eval()\n",
        "            print(\"=====================Validating=====================\")\n",
        "            eval_acc = 0.0\n",
        "            eval_loss = 0.0\n",
        "            eval_prec = 0.0\n",
        "            eval_rec = 0.0\n",
        "\n",
        "            for num,batch in enumerate(valid_data):\n",
        "              img,embeddings,label = batch[\"image\"].to(device),batch[\"embeddings\"].to(device),batch[\"label\"].to(device)\n",
        "              mask = batch[\"attn\"].to(device)\n",
        "              \n",
        "              out = self.forward(img,embeddings,mask)\n",
        "              loss = criterion(out,label)\n",
        "              [acc,precision,recall] = metrics(out,label,True,True,True)\n",
        "              \n",
        "              eval_loss+=loss.item()\n",
        "              eval_acc+=acc\n",
        "              eval_prec+=precision \n",
        "              eval_rec+=recall\n",
        "\n",
        "            valid_data_len = len(valid_data)\n",
        "            eval_loss = eval_loss / valid_data_len\n",
        "            eval_acc = eval_acc / valid_data_len\n",
        "            eval_prec = eval_prec / valid_data_len\n",
        "            eval_rec = eval_rec / valid_data_len\n",
        "\n",
        "            losses_val.append(eval_loss)\n",
        "\n",
        "            print(\"Val_loss after \",epoch+1,\" epochs: \",eval_loss)\n",
        "            print(\"Val_accuracy after \",epoch+1,\" epochs: \",eval_acc)\n",
        "\n",
        "            row = {'epoch': str(epoch+1), 'train_acc': str(train_acc), 'test_acc': str(eval_acc)}\n",
        "            csv_logger.writerow(row)\n",
        "\n",
        "        csv_logger.close()\n",
        "        return losses, losses_val"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zVe12FhrN3N"
      },
      "source": [
        "Train basline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTkep5gMwzUa"
      },
      "source": [
        "model = Base_Model()\n",
        "model.to(device)\n",
        "num_epochs = 3\n",
        "losses, losses_val = model.fit(train_data, dev_data, epochs=num_epochs)\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/DL_project/models/base_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9LmXteruPB0"
      },
      "source": [
        "# Platt Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqPSrUAlwQm2"
      },
      "source": [
        "def test_calibration(model, data):\n",
        "    model.eval()\n",
        "\n",
        "    probability = []\n",
        "    labels = []\n",
        "\n",
        "    for num,batch in enumerate(data):\n",
        "        img, embeddings, label = batch[\"image\"], batch[\"embeddings\"], batch[\"label\"]\n",
        "        mask = batch[\"attn\"]\n",
        "        prob = model.forward(img, embeddings, mask)\n",
        "        probability.extend(prob.detach().numpy())\n",
        "        labels.extend(label.numpy())\n",
        "        \n",
        "    return probability, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lewaIDYUuRzz"
      },
      "source": [
        "def platt_scaling(p, y):\n",
        "    train_end = int(y.shape[0] / 2)\n",
        "    test_start = train_end + 1\n",
        "\n",
        "    y_train = y[0:train_end]\n",
        "    y_test = y[test_start:]\n",
        "    p_train = p[0:train_end]\n",
        "    p_test = p[test_start:]\n",
        "\n",
        "    lr = LR()\n",
        "    lr.fit(p_train.reshape(-1, 1), y_train)  # LR needs X to be 2-dimensional\n",
        "    p_calibrated = lr.predict_proba(p_test.reshape(-1, 1))[:, 1]\n",
        "\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "\n",
        "    # uncalibrated\n",
        "    mean_predicted_values, true_fractions = calibration_curve(y_test, p_test, n_bins=20)\n",
        "    plt.plot(mean_predicted_values, true_fractions, marker='.', label='before calibration')\n",
        "\n",
        "    # calibrated\n",
        "    mean_predicted_values, true_fractions = calibration_curve(y_test, p_calibrated, n_bins=20)\n",
        "    plt.plot(mean_predicted_values, true_fractions, marker='.', label='after calibration')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.ylabel('fraction of positive')\n",
        "    plt.xlabel('probabilities')\n",
        "\n",
        "    plt.savefig('/content/drive/My Drive/DL_project/calibration.png', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wca-2ubbuVw_"
      },
      "source": [
        "model = Base_Model()\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/DL_project/models/base_model.pt'))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "my_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBvXMHZLwDKY"
      },
      "source": [
        "preds_original, label = test_calibration(model, dev_data)\n",
        "platt_scaling(np.array(preds_original), np.array(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P59UOY5arr4D"
      },
      "source": [
        "# Add Confidence Estimate Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAI3GrFqr68M"
      },
      "source": [
        "The idea is from Terrance DeVries, Graham W. Taylor in \"Learning Confidence for Out-of-Distribution Detection in Neural Networks\" https://arxiv.org/abs/1802.04865"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSljxGnKYNzc"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import seaborn as sns\n",
        "\n",
        "def metrics2(out, label, accuracy=True, precision=False, recall=False):\n",
        "    arr = out.detach().cpu().numpy()\n",
        "    lab = label.cpu().numpy()\n",
        "\n",
        "    pred = np.zeros_like(lab)\n",
        "    for i, a in enumerate(arr):\n",
        "        if a[0] < a[1]:\n",
        "            pred[i] = 1\n",
        "\n",
        "    ret = []\n",
        "    if accuracy:\n",
        "        acc = np.sum(lab == pred) / len(pred)\n",
        "        ret.append(acc)\n",
        "    if precision:\n",
        "        precision = precision_score(pred, lab)\n",
        "        ret.append(precision)\n",
        "    if recall:\n",
        "        recall = recall_score(pred, lab)\n",
        "        ret.append(recall)\n",
        "    return ret\n",
        "\n",
        "\n",
        "class My_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(My_Model, self).__init__()\n",
        "        self.bert_part = BERT()\n",
        "        self.batch_norm = nn.BatchNorm1d(6000)\n",
        "        self.ensemble = Ensemble()\n",
        "\n",
        "        self.confidence = nn.Linear(1536, 1) # confidence layer\n",
        "        self.fc1 = nn.Linear(1536, 6000)\n",
        "        self.fc2 = nn.Linear(6000, 3000)\n",
        "        self.fc3 = nn.Linear(3000, 1)\n",
        "\n",
        "    def forward(self, image, text, attn):\n",
        "        x1 = self.ensemble(image)\n",
        "        x2 = self.bert_part(text, attn)\n",
        "        out = torch.cat((x1, x2), dim=1)\n",
        "        c = torch.sigmoid(self.confidence(out)) # the location of confidence layer is after the merge\n",
        "\n",
        "        x3 = self.fc1(out)\n",
        "        x3 = self.batch_norm(x3)\n",
        "        x4 = F.relu(self.fc2(x3), inplace=False)\n",
        "        pred = torch.sigmoid(self.fc3(x4))\n",
        "        return pred, c\n",
        "\n",
        "    def fit(self, train_data, valid_data, budget=0.3, epochs=3):\n",
        "        losses = []\n",
        "        losses_val = []\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        optim = Adam(self.parameters(), lr=1e-5, weight_decay=0.001)\n",
        "        criterion = nn.BCELoss()\n",
        "        lmbda = 0.1\n",
        "        eps = 1e-12\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            print(\"===================== Training ====================\")\n",
        "            print(\"Epoch # \", epoch + 1)\n",
        "            train_loss = 0.0\n",
        "            train_acc = 0.0\n",
        "            train_pre = 0.0\n",
        "            train_rec = 0.0\n",
        "\n",
        "            for num, batch in enumerate(train_data):\n",
        "                img, embeddings, label = batch[\"image\"].to(device), batch[\"embeddings\"].to(device), batch[\"label\"].to(\n",
        "                    device)\n",
        "                mask = batch[\"attn\"].to(device)\n",
        "\n",
        "                out, c = self.forward(img, embeddings, mask)\n",
        "\n",
        "                out = torch.clamp(out, 0. + eps, 1. - eps)\n",
        "                c = torch.clamp(c, 0. + eps, 1. - eps)\n",
        "\n",
        "                b = Variable(torch.bernoulli(torch.Tensor(c.size()).uniform_(0, 1))).to(device)\n",
        "                confidence = c * b + (1 - b)\n",
        "                pred_new = out * confidence.expand_as(out) + label * (1 - confidence.expand_as(label))\n",
        "                \n",
        "                xentropy_loss = criterion(pred_new, label)\n",
        "                confidence_loss = torch.mean(-torch.log(c))\n",
        "                total_loss = xentropy_loss + lmbda * confidence_loss\n",
        "\n",
        "                if budget > confidence_loss.item():\n",
        "                    lmbda = lmbda / 1.01\n",
        "                elif budget <= confidence_loss.item():\n",
        "                    lmbda = lmbda / 0.99\n",
        "\n",
        "                train_loss += total_loss\n",
        "\n",
        "                [acc, prec, rec] = metrics(out, label, accuracy=True, precision=True, recall=True)\n",
        "                train_acc += acc\n",
        "                train_pre += prec\n",
        "                train_rec += rec\n",
        "\n",
        "                total_loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "\n",
        "                if num > 0 and num % 100 == 0:\n",
        "                    print(\"Loss after \", num, \" steps: \", train_loss / num)\n",
        "                    print(\"Accuracy after \", num, \" steps: \", train_acc / num)\n",
        "\n",
        "            train_loss = train_loss / num\n",
        "            train_acc = train_acc / num\n",
        "            train_pre = train_pre / num\n",
        "            train_rec = train_rec / num\n",
        "\n",
        "            losses.append(train_loss)\n",
        "\n",
        "            print(\"----------------After epoch \", epoch + 1, \"-------------------------\")\n",
        "            print(\"Loss after \", num, \" steps: \", train_loss)\n",
        "            print(\"Accuracy after \", num, \" steps: \", train_acc)\n",
        "\n",
        "        return losses, losses_val"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7x4CPUus8CI"
      },
      "source": [
        "Train confidence estimate layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRpm5eyyY6bl",
        "outputId": "372ac5e2-7d75-489e-81d8-622621a4605b"
      },
      "source": [
        "my_model = My_Model()\n",
        "my_model.to(device)\n",
        "\n",
        "num_epochs = 3\n",
        "losses, losses_val = my_model.fit(train_data, dev_data, budget=0.3, epochs=num_epochs)\n",
        "torch.save(my_model.state_dict(), '/content/drive/My Drive/DL_project/models/my_model.pt')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===================== Training ====================\n",
            "Epoch #  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss after  100  steps:  tensor(0.6125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  100  steps:  0.5825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss after  200  steps:  tensor(0.6313, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  200  steps:  0.596875\n",
            "Loss after  300  steps:  tensor(0.6275, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  300  steps:  0.6129166666666667\n",
            "Loss after  400  steps:  tensor(0.6188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  400  steps:  0.6221875\n",
            "Loss after  500  steps:  tensor(0.6081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  500  steps:  0.637\n",
            "Loss after  600  steps:  tensor(0.6005, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  600  steps:  0.645625\n",
            "Loss after  700  steps:  tensor(0.5900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  700  steps:  0.6564285714285715\n",
            "Loss after  800  steps:  tensor(0.5875, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  800  steps:  0.66078125\n",
            "Loss after  900  steps:  tensor(0.5781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  900  steps:  0.6718055555555555\n",
            "Loss after  1000  steps:  tensor(0.5700, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1000  steps:  0.6785\n",
            "----------------After epoch  1 -------------------------\n",
            "Loss after  1062  steps:  tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1062  steps:  0.6796139359698682\n",
            "===================== Training ====================\n",
            "Epoch #  2\n",
            "Loss after  100  steps:  tensor(0.4799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  100  steps:  0.78375\n",
            "Loss after  200  steps:  tensor(0.4621, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  200  steps:  0.7775\n",
            "Loss after  300  steps:  tensor(0.4768, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  300  steps:  0.76375\n",
            "Loss after  400  steps:  tensor(0.4796, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  400  steps:  0.75625\n",
            "Loss after  500  steps:  tensor(0.4788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  500  steps:  0.75925\n",
            "Loss after  600  steps:  tensor(0.4788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  600  steps:  0.7591666666666667\n",
            "Loss after  700  steps:  tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  700  steps:  0.7583928571428571\n",
            "Loss after  800  steps:  tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  800  steps:  0.7596875\n",
            "Loss after  900  steps:  tensor(0.4713, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  900  steps:  0.7638888888888888\n",
            "Loss after  1000  steps:  tensor(0.4728, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1000  steps:  0.76425\n",
            "----------------After epoch  2 -------------------------\n",
            "Loss after  1062  steps:  tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1062  steps:  0.7634180790960452\n",
            "===================== Training ====================\n",
            "Epoch #  3\n",
            "Loss after  100  steps:  tensor(0.3537, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  100  steps:  0.835\n",
            "Loss after  200  steps:  tensor(0.3604, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  200  steps:  0.82125\n",
            "Loss after  300  steps:  tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  300  steps:  0.8183333333333334\n",
            "Loss after  400  steps:  tensor(0.3840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  400  steps:  0.8096875\n",
            "Loss after  500  steps:  tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  500  steps:  0.81025\n",
            "Loss after  600  steps:  tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  600  steps:  0.804375\n",
            "Loss after  700  steps:  tensor(0.3998, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  700  steps:  0.8016071428571429\n",
            "Loss after  800  steps:  tensor(0.3982, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  800  steps:  0.80453125\n",
            "Loss after  900  steps:  tensor(0.3958, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  900  steps:  0.8061111111111111\n",
            "Loss after  1000  steps:  tensor(0.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1000  steps:  0.806625\n",
            "----------------After epoch  3 -------------------------\n",
            "Loss after  1062  steps:  tensor(0.3981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy after  1062  steps:  0.8053201506591338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v8iryMstXJ0"
      },
      "source": [
        "Plot the confidence Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym7rdbxDz5g3"
      },
      "source": [
        "my_model = My_Model()\n",
        "my_model.load_state_dict(torch.load('/content/drive/My Drive/DL_project/models/my_model.pt'))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "my_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9fcgcelY6OP"
      },
      "source": [
        "def plot_histograms(conf_1, conf_2, out_type = 'Confidence', bins=100, norm_hist=True):\n",
        "    global conf_histogram\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.distplot(conf_1, kde=False, bins=bins, norm_hist=norm_hist, label='Train Data')\n",
        "    sns.distplot(conf_2, kde=False, bins=bins, norm_hist=norm_hist, label='Test Data')\n",
        "    \n",
        "    plt.xlabel(out_type)\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/content/drive/My Drive/DL_project/\" + out_type + \"_histogram.png\")\n",
        "\n",
        "\n",
        "def test_confidence(model, data):\n",
        "\n",
        "    model.eval()\n",
        "    confidence = []\n",
        "\n",
        "    for num,batch in enumerate(data):\n",
        "      img,embeddings= batch[\"image\"].to(device),batch[\"embeddings\"].to(device)\n",
        "      mask = batch[\"attn\"].to(device)\n",
        "      out, conf = model.forward(img,embeddings,mask)\n",
        "      confidence.extend(conf.detach().cpu().numpy())\n",
        "    \n",
        "    confidence = np.array(confidence)\n",
        "\n",
        "    return confidence"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxbYeap0DCrr"
      },
      "source": [
        "train_data = preprocess_data(\"data/train.jsonl\", label=True)\n",
        "conf_1 = test_confidence(my_model, train_data)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPSjrp0XC_Kf"
      },
      "source": [
        "test_data = preprocess_data(\"data/dev_seen.jsonl\", label=False)\n",
        "conf_2 = test_confidence(my_model, test_data)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "hMclDvQf7FaC",
        "outputId": "327834bf-662b-417f-ceda-8586e86c7067"
      },
      "source": [
        "plot_histograms(conf_1, conf_2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbtUlEQVR4nO3de5RcdZXo8e8m5uFAGF5BWMTYIWN4yCNAO0HQkYiICkQMMvJyQJSIqFwZL8ggXBkfSxzX0jt4dZjgA1GijsEEfMzMFSUEBkxMJgECgcFAjGEQQmJCcllgAvv+UZVQafpR/ThVp6q/n7WyuurUqd/Zv67u3vn9zu/sE5mJJElls1OzA5AkqTsmKElSKZmgJEmlZIKSJJWSCUqSVEqvaHYAtfbaa6/s6OhodhiSpAZasmTJ05k5ruv2UiWojo4OFi9e3OwwJEkNFBG/6267U3ySpFIyQUmSSskEJUkqpVKdg+rOli1bWLNmDc8991yzQ2krY8aMYfz48YwcObLZoUhSt0qfoNasWcPYsWPp6OggIpodTlvITNatW8eaNWuYOHFis8ORpG6VforvueeeY8899zQ5DaGIYM8993RUKqnUSp+gAJNTAfyeSiq7lkhQkqThp/TnoLqavXD1kLZ31tQJPb62bt06jj/+eAD+8Ic/MGLECMaNq1zsvGjRIkaNGtXjexcvXsyNN97ItddeW3csHR0djB07FoAXXniBGTNmcOWVVzJmzJge37NhwwZmz57NRRddVPdxJKkVOILqxZ577smyZctYtmwZF154IZdccsn256NGjWLr1q09vrezs7NfyWmb22+/nfvvv59Fixbx6KOP8qEPfajX/Tds2MDXv/71fh9HksrOBNVP5513HhdeeCFTp07lsssuY9GiRbzhDW/giCOO4JhjjuHhhx8GYP78+Zx88skAXH311Zx//vkcd9xx7L///nUlrl122YXrrruOefPmsX79ejZv3szxxx/PkUceyaGHHsott9wCwOWXX87KlSuZMmUKl156aY/7SVKt2QtXb/9XVi03xVcGa9as4e6772bEiBE888wz3HnnnbziFa/gtttu44orruDmm29+2Xseeughbr/9djZt2sQBBxzAhz/84T6vQdp1112ZOHEijzzyCEcddRRz585l11135emnn+boo49m+vTpXHPNNSxfvpxly5YBsHXr1m73c1GEpFZjghqA008/nREjRgCwceNGzj33XB555BEigi1btnT7npNOOonRo0czevRo9t57b5588knGjx/f57Eyc/vXK664ggULFrDTTjvx+OOP8+STT3a7f3f77bPPPoPosSQ1nglqAHbeeeftj6+66iqmTZvG3LlzWbVqFccdd1y37xk9evT2xyNGjOj1/NU2mzZtYtWqVUyePJmbbrqJtWvXsmTJEkaOHElHR0e31zHVu58klZ3noAZp48aN7LfffgDccMMNQ9bu5s2bueiiizj11FPZfffd2bhxI3vvvTcjR47k9ttv53e/q1SnHzt2LJs2bdohnu72k6RW03IjqN6WhTfDZZddxrnnnsvnPvc5TjrppEG3N23aNDKTF198kXe/+91cddVVAJx99tmccsopHHrooXR2dnLggQcClZWGxx57LIcccgjveMc7+OQnP9ntfpLUamLbOY4y6OzszK43LFyxYgUHHXRQkyJqb35vpeGrdvVes//jHxFLMrOz63an+CRJpWSCkiSVkglKklRKJihJUimZoCRJpWSCkiSVUstdB8Xibw9te53v7/GlwdxuAyoFY0eNGsUxxxzzstduuOEGLr30UsaPH8/mzZvZf//9+fSnP93tvrXmzZvH5MmTOfjgg/vqmaThrvbvZS9/68rKEVQv+rrdRl/mz5/P3Xff3ePr733ve1m6dCmPPPIIl19+OTNmzGDFihW9tjlv3jwefPDBfvdFklqNCaqflixZwpvf/GaOOuooTjzxRJ544gkArr32Wg4++GAOO+wwzjjjDFatWsV1113HV77yFaZMmcKdd97Za7vTpk1j5syZzJo1C4Drr7+e17/+9Rx++OGcdtppPPvss9x9993ceuutXHrppUyZMoWVK1d2u58ktQMTVD9kJh/72MeYM2cOS5Ys4fzzz+dTn/oUANdccw1Lly7lvvvu47rrrqOjo2OHUdeb3vSmPts/8sgjeeihhwCYMWMGv/nNb7j33ns56KCD+OY3v8kxxxzD9OnT+dKXvsSyZcuYNGlSt/tJUjtovXNQTfT888+zfPlyTjjhBKByW/Z9990XgMMOO4yzzz6bU089lVNPPXVA7deWnVq+fDlXXnklGzZsYPPmzZx44ondvqfe/SSp1Zig+iEzed3rXsc999zzstd+9rOfsWDBAn7yk5/w+c9/nvvvv7/f7S9dunR7bbzzzjuPefPmcfjhh3PDDTcwf/78bt9T736S1Gqc4uuH0aNHs3bt2u0JasuWLTzwwAO8+OKL/P73v2fatGl88YtfZOPGjWzevPllt8LozR133MGsWbO44IILgMq9oPbdd1+2bNnCTTfdtH2/rm32tJ8ktbrWG0E1cankTjvtxJw5c7j44ovZuHEjW7du5eMf/ziTJ0/mnHPOYePGjWQmF198MbvtthunnHIK73nPe7jlllv46le/+rLzUD/84Q+56667ePbZZ5k4cSI333zz9hHUZz/7WaZOncq4ceOYOnXq9qR0xhlncMEFF3DttdcyZ86cHveTpFZX6O02ImIVsAl4AdjaXTn1Wt5uo7H83kptrpfroFrhdhuNGEFNy8ynG3AcSVIb8RyUJKmUik5QCfzfiFgSETO72yEiZkbE4ohYvHbt2u4bKdFdf9uF31NJZVd0gnpjZh4JvAP4SET8VdcdMnNWZnZmZue2One1xowZw7p16/yDOoQyk3Xr1jFmzJhmhyJJPSr0HFRmPl79+lREzAX+EljQnzbGjx/PmjVr6Gl0pYEZM2YM48ePb3YYkvqjxYu/9ldhCSoidgZ2ysxN1cdvAz7T33ZGjhzJxIkThzw+SVK5FTmCehUwNyK2HWd2Zv5bgceTJLWRwhJUZj4KHF5U+5Kk+tVe99QqXGYuSSql1it1JEmqy8LH1r/0pLnFIgbEEZQkqZQcQUnSMNf1/FSza/Nt4whKklRKJihJUimZoCRJpWSCkiSVkglKklRKJihJUim5zFySijTMKpAPJUdQkqRSMkFJkkrJBCVJKiUTlCSplExQkqRSMkFJkkrJBCVJKiUTlCSplExQkqRSMkFJkkrJBCVJKiUTlCSplCwWK0llVltstqftbVqE1hGUJKmUTFCSpFIyQUmSSskEJUkqJROUJKmUXMUnSdrB7IWrtz8+a+qEpsXhCEqSVEqFJ6iIGBERSyPip0UfS5LUPhoxgvofwIoGHEeS1EYKTVARMR44CfhGkceRJLWfohdJ/G/gMmBsTztExExgJsCECc07GSdJra52cQPApCbFMVQKG0FFxMnAU5m5pLf9MnNWZnZmZue4ceOKCkeS1GKKnOI7FpgeEauAHwBviYjvFXg8SVIbKSxBZebfZeb4zOwAzgB+lZnnFHU8SVJ78UJdSWohCx9bv8PzqRP3aFIkxWtIgsrM+cD8RhxLktQeHEFJUgtb+Nh6Vr6wuu8dW5CljiRJpWSCkiSVkglKklRKJihJUimZoCRJpWSCkiSVkglKklRKJihJUil5oa6k8lv87Zced76/eXEMpSHs06TVPxpkMOXkCEqSVEomKElSKZmgJEml5DkoSSq5rrfYGC4cQUmSSskEJUkqJROUJKmUTFCSpFIyQUmSSskEJUkqpboSVET8OCJOiggTmiSpIepNOF8HzgIeiYhrIuKAAmOSJKm+C3Uz8zbgtoj4c+DM6uPfA9cD38vMLQXGKLWndiyAOljD9XvS4H53LS67csLphR9zIOquJBERewLnAO8DlgI3AW8EzgWOKyI4SRqOZi9cvf3xpNXDs4oE1JmgImIucADwXeCUzHyi+tIPI2JxUcFJkoavekdQ12fmz2s3RMTozHw+MzsLiEuSNMzVu0jic91su2coA5EkqVavI6iI2AfYD3hlRBwBRPWlXYE/Kzg2SdIw1tcU34nAecB44Ms12zcBVxQUkyRJvSeozPwO8J2IOC0zb25QTJIk9TnFd05mfg/oiIi/7fp6Zn65m7dJkjRofU3x7Vz9ukt/G46IMcACYHT1OHMy89P9bUeSNDz1NcX3z9Wvfz+Atp8H3pKZmyNiJHBXRPxrZv56AG1JkoaZeovF/kNE7BoRIyPilxGxNiLO6e09WbG5+nRk9V8OMl5J0jBR73VQb8vMZ4CTgVXAXwCX9vWmiBgREcuAp4BfZObCbvaZGRGLI2Lx2rVr649cktTW6q0ksW2/k4AfZebGiOhtfwAy8wVgSkTsBsyNiEMyc3mXfWYBswA6OzsdYal11Bb4BIubDkVbrayFC93WFo8tU+HYekdQP42Ih4CjgF9GxDjguXoPkpkbgNuBt/c/REnScFRXgsrMy4FjgM7qrTX+H/Cu3t4TEeOqIyci4pXACcBDgwtXkjRc1H27DeBAKtdD1b7nxl7235fKRb4jqCTCf8nMnw4gRknSMFTv7Ta+C0wClgEvVDcnvSSozLwPOGKwAUqShqd6R1CdwMGZ6SIGSRqg2hsRnjWiiYG0iHoT1HJgH+CJvnaUJPVt4WM73il36sQ9mhRJedWboPYCHoyIRVQqRACQmdMLiUqSVAq1oz6As6ZOaNix601QVxcZhCRJXdWVoDLzjoh4DfDazLwtIv4McAZVklSYemvxXQDMAf65umk/YF5RQUmSVG8liY8AxwLPAGTmI8DeRQUlSVK9Cer5zPzTtifVi3Vdci5JKky9iyTuiIgrgFdGxAnARcBPigtLklrTwsfWs/KFysq3/qx427bsfNt7VX+Cuhz4AHA/8CHg58A3igpKUj+1cCXtfiuqkvpA2mqhSuy1FctbRb2r+F6MiHnAvMz0pk2SpML1eg4qKq6OiKeBh4GHq3fT/V+NCU+SNFz1tUjiEiqr916fmXtk5h7AVODYiLik8OgkScNWXwnqfcCZmfnYtg2Z+ShwDvA3RQYmSRre+kpQIzPz6a4bq+ehRhYTkiRJfSeoPw3wNUmSBqWvVXyHR8Qz3WwPYEwB8UiSBPSRoDLTgrCSpKaot9SRJEkNZYKSJJWSCUqSVEomKElSKdVbLFYavoZTIdZW09tn09/PrZ79q/tsqzyuYjmCkiSVkiMoSU1VOxqZOnGPwo83e+FL91s6qx8X0sxeuJpJqx05NZIjKElSKTmCktR2akc7jRiVqRiOoCRJpWSCkiSVklN8klpSoxdXqPEcQUmSSqmwEVREvBq4EXgVkMCszPzHoo4nSWXzsqXpE5oXSysqcopvK/CJzPzPiBgLLImIX2TmgwUeU5LUJgpLUJn5BPBE9fGmiFgB7AeYoCSVQteSRbXnsmov6FVzNGSRRER0AEcAC7t5bSYwE2DCBMe/kl6yLUlMWr3ehRDDUOEJKiJ2AW4GPp6ZL7t9fGbOAmYBdHZ2ZtHxSE1VW5C0rAZTZLVW7Xsb0e+aY/RWkmjS6h/1q9n+7t/qavu7csLpTYyk4AQVESOpJKebMvPHRR5LUs+6TledNdXZCpVfYcvMIyKAbwIrMvPLRR1HktSeirwO6ljgfcBbImJZ9d87CzyeJKmNFLmK7y4gimpfktTeLHUkaUB6W6JdJgsfW8/KF146Bzepj32BHfZX85igJNWtdtl3o3mb9eHHBCWpoUw0qpcJStIOdqgS3tnEQDTsmaCkYa7rNVK9naMpK0dl7ckEJalH/alH5/2ZNNS8H5QkqZRMUJKkUnKKT+XS30KlrXC8egqlDkEcXa/hOWvqhO3tTlq9vvGFP1uhMG4PBlsgtl0KzDa7cKwjKElSKTmCklQ4V9lpIExQkobcQBNS7fssNySn+CRJpeQISupG7fU/ZbvdeG1s3nhQ7cwEJbWwZhZvlYpmgpIGqXZ5dxEjmv5Uc5DaiQlKKqGhSEqzF652ZKWW5iIJSVIpOYKS+mmozvv0tBS7EcurnTZUK3AEJUkqJUdQ0hDqOjJxGbg0cCYoDUx/i5sOpBjqYAqodi1UWvv+noqY7rD9+P4dr4vtRTZHDO76qd6KjvZUvLOn9/RU+LO3YzSz6Gm7FFyt1cp92uFnuhGFnHGKT5JUUo6gpDp0vZWFpOI5gpIklZIjKKlA3mZCGjhHUJKkUjJBSZJKySk+tTyvPZLakwlKw1bX80NluueTJBOU2lzX5eGOrqTWUViCiohvAScDT2XmIUUdRxoqO4yozGNS0xW5SOIG4O0Fti/12+yFq1n42HqXf0stoLAElZkLAP8KSJIGpOnnoCJiJjATYMIE51WG3GAKrraCxd9+2X2ZurvV0VAV6WxEsc9WLiiqwfPzf0nTr4PKzFmZ2ZmZnePGjWt2OJKkkmh6gpIkqTsmKElSKRWWoCLi+8A9wAERsSYiPlDUsdSetq22c8WdNDwVtkgiM88sqm0NP5YzkoYfp/gkSaVkgpIklZIJSpJUSk2/UFfDy8LH1m8v3NqV55Uk1TJBqSVtWzTRtYqEpPZhglLhZi9cbSKR1G+eg5IklZIjqEYbyuKtZS8EW42v6+ipp2KY3RV57es9Gpjh9v0cbv1tF46gJEml5AhKQ6K20oOr8aT2VbsSt+jfdUdQkqRSMkFJkkrJKT7VrXYab9Lq9UyduEev+7m0XNJgOIKSJJWSCUqSVEomKElSKXkOSgO27U63PRV/laTBcAQlSSolR1DDkLdPl9QKHEFJkkrJBCVJKiWn+IpSW2m8QcfbvmhhwundT9v1UF2cEd1fcAsvLYQAmNTDPrWVoldOOL2+eEtuINWvG10x2wrdancmKO2gNiFJUjOZoErIyuCSZIISjpoklZMJqk1ZsFVSqzNBlUDX65IkSSaolrPD+akRTQxEkgpmgmqQrud5erqXUle9ja48dySpnZmgmmThY+stsipJvTBBDZJLwiWpGIUmqIh4O/CPwAjgG5l5TZHHKxun4CRp4ApLUBExAvgacAKwBvhNRNyamQ8Wdcy+9Dbaqfe1ett3ebckDU6RI6i/BH6bmY8CRMQPgHcBhSYop9wkqT1EZhbTcMR7gLdn5gerz98HTM3Mj3bZbyYws/r0AODhPpreC3h6iMNtpnbqTzv1BdqrP+3UF2iv/rRTX2Bg/XlNZo7rurHpiyQycxYwq979I2JxZnYWGFJDtVN/2qkv0F79aae+QHv1p536AkPbnyLvB/U48Oqa5+Or2yRJ6lORCeo3wGsjYmJEjALOAG4t8HiSpDZS2BRfZm6NiI8C/05lmfm3MvOBIWi67unAFtFO/WmnvkB79aed+gLt1Z926gsMYX8KWyQhSdJgFDnFJ0nSgJmgJEmlVNoEFRFvj4iHI+K3EXF5N69fGBH3R8SyiLgrIg5uRpz16KsvNfudFhEZEaVeclrHZ3NeRKytfjbLIuKDzYizHvV8NhHx1xHxYEQ8EBGzGx1jf9Tx2Xyl5nP5r4jY0Iw461FHXyZExO0RsTQi7ouIdzYjznrV0Z/XRMQvq32ZHxHjmxFnPSLiWxHxVEQs7+H1iIhrq329LyKOHNCBMrN0/6gsqlgJ7A+MAu4FDu6yz641j6cD/9bsuAfal+p+Y4EFwK+BzmbHPcjP5jzg/zQ71iHqy2uBpcDu1ed7Nzvuwf6s1ez/MSqLl5oe+wA/m1nAh6uPDwZWNTvuQfbnR8C51cdvAb7b7Lh76c9fAUcCy3t4/Z3AvwIBHA0sHMhxyjqC2l4mKTP/BGwrk7RdZj5T83RnoKyrPfrsS9VngS8CzzUyuAGotz+toJ6+XAB8LTP/CJCZTzU4xv7o72dzJvD9hkTWf/X0JYFdq4//HPjvBsbXX/X052DgV9XHt3fzemlk5gKgt4Kj7wJuzIpfA7tFxL79PU5ZE9R+wO9rnq+pbttBRHwkIlYC/wBc3KDY+qvPvlSHv6/OzJ81MrABquuzAU6rDu3nRMSru3m9DOrpy2RgckT8R0T8ulqhv6zq/WyIiNcAE3npD2LZ1NOXq4FzImIN8HMqI8Kyqqc/9wIzqo/fDYyNiD0bEFsR6v5Z7E1ZE1RdMvNrmTkJ+CRwZbPjGYiI2An4MvCJZscyhH4CdGTmYcAvgO80OZ7BeAWVab7jqIw4ro+I3Zoa0dA4A5iTmS80O5BBOBO4ITPHU5lS+m7196lV/U/gzRGxFHgzlco7rfz5DFpZP8z+lkn6AXBqoRENXF99GQscAsyPiFVU5mtvLfFCiT4/m8xcl5nPV59+AziqQbH1Vz0/Z2uAWzNzS2Y+BvwXlYRVRv35vTmD8k7vQX19+QDwLwCZeQ8whkqh0jKq5/fmvzNzRmYeAXyquq20i1j6MCSl7sqaoPoskxQRtX8kTgIeaWB8/dFrXzJzY2bulZkdmdlBZZHE9Mxc3Jxw+1TPZ1M71zwdWNHA+PqjnnJc86iMnoiIvahM+T3ayCD7oa7yYhFxILA7cE+D4+uPevqyGjgeICIOopKg1jY0yvrV83uzV80I8O+AbzU4xqF0K/A31dV8RwMbM/OJ/jbS9Grm3ckeyiRFxGeAxZl5K/DRiHgrsAX4I3Bu8yLuWZ19aRl19ufiiJgObKVyIvW8pgXcizr78u/A2yLiQSrTLZdm5rrmRd2zfvysnQH8IKvLrcqozr58gsqU6yVUFkycV9Y+1dmf44AvRERSWdH7kaYF3IeI+D6VePeqngP8NDASIDOvo3JO8J3Ab4FngfcP6Dgl/TwlScNcWaf4JEnDnAlKklRKJihJUimZoCRJpWSCkiSVkglK6kFE7BMRP4iIlRGxJCJ+HhGTB9DOm6qV0JdFxH4RMaeH/eaX+AJtqeFMUFI3IiKAucD8zJyUmUdRuXjyVQNo7mzgC5k5JTMfz8z3DGWsUrsyQUndmwZsqV50CEBm3gvcFRFfiojlUbkf2XsBIuK46ghoTkQ8FBE3Va+i/yDw18Bnq9s6tt1DJyJeWR2hrYiIucArtx0rIt4WEfdExH9GxI8iYpfq9lUR8ffV7fdXq0IQEbtExLer2+6LiNN6a0dqBSYoqXuHAEu62T4DmAIcDrwV+FJNaacjgI9TuW3C/sCxmfkNKmVfLs3Ms7u09WHg2cw8iMqV+EfB9pJKVwJvzcwjgcXA39a87+nq9n+iUmAU4Coq5WQOrRbp/VUd7UilVspSR1KJvRH4frUK+JMRcQfweuAZYFFmrgGIiGVAB3BXL239FXAtQGbeFxH3VbcfTSXJ/UdlppFR7Fg378fVr0t46fYMb6VSwohqe3+MiJP7aEcqNROU1L0HgP6eK3q+5vELDPz3K4BfZOaZfRynr2P01Y5Uak7xSd37FTA6ImZu2xARhwEbgPdGxIiIGEdlFLRogMdYAJxVbfsQ4LDq9l8Dx0bEX1Rf27mO1YO/oKa4aETsPsB2pNIwQUndqFbFfjfw1uoy8weALwCzgfuo3P30V8BlmfmHAR7mn4BdImIF8Bmq57wycy2VCvDfr0773QMc2EdbnwN2ry7euBeYNsB2pNKwmrkkqZQcQUmSSskEJUkqJROUJKmUTFCSpFIyQUmSSskEJUkqJROUJKmU/j+ewZ5xSNuz6AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}